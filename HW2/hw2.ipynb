{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "「「SHARE MLSpring20.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2-1 Phoneme Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emUd7uS7crTz"
      },
      "source": [
        "## The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus (TIMIT)\n",
        "The TIMIT corpus of reading speech has been designed to provide speech data for the acquisition of acoustic-phonetic knowledge and for the development and evaluation of automatic speech recognition systems.\n",
        "\n",
        "This homework is a multiclass classification task, \n",
        "we are going to train a deep neural network classifier to predict the phonemes for each frame from the speech corpus TIMIT.\n",
        "\n",
        "link: https://academictorrents.com/details/34e2b78745138186976cbc27939b1b34d18bd5b3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgouVBJdJYBy"
      },
      "source": [
        "### **Download data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkiMEcC3Foq",
        "outputId": "5f1af1db-b6c4-45cf-cd60-67d3ded2747e"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "# 要檢查的檔案路徑\n",
        "filepath = \"/content/data.zip\"\n",
        "\n",
        "# 檢查檔案是否存在\n",
        "if os.path.isfile(filepath):\n",
        "  print(\"檔案存在。\")\n",
        "  pass\n",
        "else:\n",
        "  print(\"檔案不存在。\")\n",
        "  !gdown --id '1seDU182JBfqxkGa503aSS-TRYRf0N5p3' --output data.zip\n",
        "  !unzip data.zip\n",
        "  !ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "檔案存在。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwh1fruoUoAn"
      },
      "source": [
        "## release RAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ3xbx9aUnKK"
      },
      "source": [
        "\n",
        "# torch.cuda.empty_cache\n",
        "# !nvidia-smi\n",
        "#!kill process_id\n",
        "# import os, signal\n",
        "# os.kill(os.getpid(), signal.SIGKILL)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "## Preparing Data\n",
        "Load the training and testing data from the `.npy` file (NumPy array)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJjLT8em-y9G",
        "outputId": "a20b49bd-23cc-478a-ed6b-dc404484c061"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "print('Loading data ...')\n",
        "\n",
        "data_root='./timit_11/'\n",
        "train = np.load(data_root + 'train_11.npy')\n",
        "train_label = np.load(data_root + 'train_label_11.npy')\n",
        "test = np.load(data_root + 'test_11.npy')\n",
        "\n",
        "print('Size of training data: {}'.format(train.shape))\n",
        "print('Size of testing data: {}'.format(test.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data ...\n",
            "Size of training data: (1229932, 429)\n",
            "Size of testing data: (451552, 429)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN_3kKvtaI6o"
      },
      "source": [
        "# data size<br>\n",
        "**Size of training data: (1229932, 429)<br>**\n",
        "**Size of testing data: (451552, 429)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjf5EcmJtf4e"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TIMITDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = torch.from_numpy(X).float()\n",
        "        if y is not None:\n",
        "            y = y.astype(np.int)\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otIC6WhGeh9v"
      },
      "source": [
        "Split the labeled data into a training set and a validation set, you can modify the variable `VAL_RATIO` to change the ratio of validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYqi_lAuvC59",
        "outputId": "8f20a417-0f6a-45b4-ccf1-e8404261f105"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "VAL_RATIO = 0.1 #0.2\n",
        "\n",
        "train_x, val_x = train_test_split(train, random_state=31, train_size=(1-VAL_RATIO) )\n",
        "\n",
        "train_y, val_y = train_test_split(train_label, random_state=31, train_size=(1-VAL_RATIO) )\n",
        "\n",
        "\n",
        "print('Size of training set: {}'.format(train_x.shape))\n",
        "print('Size of validation set: {}'.format(val_x.shape))\n",
        "\n",
        "\n",
        "# percent = int(train.shape[0] * (1 - VAL_RATIO))\n",
        "\n",
        "# train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\n",
        "# print('Size of training set: {}'.format(train_x.shape))\n",
        "# print('Size of validation set: {}'.format(val_x.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training set: (1106938, 429)\n",
            "Size of validation set: (122994, 429)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30ov1dVJpM64"
      },
      "source": [
        "# Size of training set: (983945, 429)</br>\n",
        "# Size of validation set: (245987, 429)</br>\n",
        "983945 = 5x47x53x79</br>\n",
        "245987 = 7x35141"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbCfclUIgMTX"
      },
      "source": [
        "Create a data loader from the dataset, feel free to tweak the variable `BATCH_SIZE` here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUCbQvqJurYc"
      },
      "source": [
        "import torch\n",
        "BATCH_SIZE = 200 #64\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = TIMITDataset(train_x, train_y)\n",
        "val_set = TIMITDataset(val_x, val_y)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SY7X0lUgb50"
      },
      "source": [
        "Cleanup the unneeded variables to save memory.<br>\n",
        "\n",
        "**notes: if you need to use these variables later, then you may remove this block or clean up unneeded variables later<br>the data size is quite huge, so be aware of memory usage in colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8rzkGraeYeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e7b61a-2356-4ba0-f754-50bb29ff6515"
      },
      "source": [
        "import gc\n",
        "del train, train_label, train_x, train_y, val_x, val_y\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYr1ng5fh9pA"
      },
      "source": [
        "Define model architecture, you are encouraged to change and experiment with the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbZrwT6Ny0XL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "\n",
        "        self.convolutionA = nn.Conv1d(in_channels=1, out_channels=39, kernel_size=10, stride=5, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "        self.flattenA = nn.Flatten(start_dim=1)\n",
        "\n",
        "        self.convolutionB = nn.Conv1d(in_channels=20, out_channels=39, kernel_size=10, stride=5, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "        self.flattenB = nn.Flatten(start_dim=1)\n",
        "\n",
        "\n",
        "        # self.convolutionC = nn.Conv1d(in_channels=39, out_channels=80, kernel_size=10, stride=5, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "        self.flattenC = nn.Flatten(start_dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.layer1 = nn.Linear(3276, 1024) #429, 1024  check input neuron number with print(x)\n",
        "\n",
        "        self.layer2 = nn.Linear(1024, 512) #1024, 512\n",
        "\n",
        "\n",
        "        self.layer3 = nn.Linear(512, 256) #512, 128\n",
        "\n",
        "\n",
        "        self.layer4 = nn.Linear(256, 128) #512, 128\n",
        "\n",
        "\n",
        "        self.out = nn.Linear(128, 39)  #128, 39\n",
        "\n",
        "        self.batchnormA = nn.BatchNorm1d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.batchnormB = nn.BatchNorm1d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        self.batchnormC = nn.BatchNorm1d(585, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        self.batchnorm1 = nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.batchnorm4 = nn.BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        self.act_fnA = nn.ReLU()\n",
        "        self.act_fnB = nn.ReLU()\n",
        "        self.act_fnC = nn.ReLU()\n",
        "\n",
        "        self.act_fn1 = nn.ReLU()\n",
        "        self.act_fn2 = nn.ReLU()\n",
        "        self.act_fn3 = nn.ReLU()\n",
        "        self.act_fn4 = nn.ReLU()\n",
        "        #self.act_fn = nn.Sigmoid()\n",
        "\n",
        "\n",
        "\n",
        "        self.dtA = nn.Dropout(p=0.5)\n",
        "        self.dtB = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.dtC = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.dt1 = nn.Dropout(p=0.5)\n",
        "        self.dt2 = nn.Dropout(p=0.5)\n",
        "        self.dt3 = nn.Dropout(p=0.5)\n",
        "        self.dt4 = nn.Dropout(p=0.5)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # print(x)\n",
        "        # print(x.shape)\n",
        "        \n",
        "\n",
        "        x = x.reshape(x.shape[0], 1, 429)\n",
        "\n",
        "\n",
        "        x = self.convolutionA(x)\n",
        "        x = self.batchnormA(x)\n",
        "        x = self.act_fnA(x)\n",
        "        x = self.dtA(x)\n",
        "        \n",
        "\n",
        "        # x = self.convolutionB(x)\n",
        "        # x = self.batchnormB(x)\n",
        "        # x = self.act_fnB(x)\n",
        "        # x = self.dtB(x)\n",
        "\n",
        "        # x = self.convolutionC(x)\n",
        "        # x = self.batchnormC(x)\n",
        "        # x = self.act_fnC(x)\n",
        "        # x = self.dtC(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # print(x.shape)\n",
        "\n",
        "\n",
        "        x = self.flattenA(x)\n",
        "\n",
        "        # print(x.shape)\n",
        "\n",
        "\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.act_fn1(x)\n",
        "        x = self.dt1(x)\n",
        "\n",
        "\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.act_fn2(x)\n",
        "        x = self.dt2(x)\n",
        "\n",
        "\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.act_fn3(x)\n",
        "        x = self.dt3(x)\n",
        "\n",
        "\n",
        "\n",
        "        x = self.layer4(x)\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.act_fn4(x)\n",
        "        x = self.dt4(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRYciXZvPbYh"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y114Vmm3Ja6o"
      },
      "source": [
        "#check device\n",
        "def get_device():\n",
        "  return 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEX-yjHjhGuH"
      },
      "source": [
        "Fix random seeds for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88xPiUnm0tAd"
      },
      "source": [
        "# fix random seed\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  \n",
        "    np.random.seed(seed)  \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbBcBXkSp6RA"
      },
      "source": [
        "Feel free to change the training parameters here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu2VD-Z8eXpF"
      },
      "source": [
        "# *optimizer*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykWUnT4hvXj9",
        "outputId": "4babeb99-74ac-4567-a6eb-a6dbb9191bcc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlStiRCvwFbG"
      },
      "source": [
        "# unmount\n",
        "# drive.flush_and_unmount()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTp3ZXg1yO9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eace4fe3-9e2a-4471-a4df-3b763b28a530"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "same_seeds(0)\n",
        "\n",
        "# get device \n",
        "device = get_device()\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# training parameters\n",
        "num_epoch = 1000               # number of training epoch\n",
        "learning_rate = 0.0001       # learning rate\n",
        "\n",
        "\n",
        "# the path where checkpoint saved\n",
        "model_path = './model.ckpt'\n",
        "model_pathgd = '/content/drive/MyDrive/model.ckpt'\n",
        "pred_path = './prediction.csv'\n",
        "pred_pathgd = '/content/drive/MyDrive/prediction.csv'\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier().to(device)\n",
        "\n",
        "\n",
        "# may load checkpoint\n",
        "# model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-05, amsgrad=False)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HktqZjT5j1Qo"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download(\"model.ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdMWsBs7zzNs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cbcc596-409a-4b48-e700-d9639389f873"
      },
      "source": [
        "# start training\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# pred in time\n",
        "# create testing dataset\n",
        "test_set = TIMITDataset(test, None)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(num_epoch):\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    val_last = 0.0\n",
        "    lastvalacc = 0.0\n",
        "\n",
        "    # training\n",
        "    model.train() # set the model to training mode\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # print(i)\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(inputs) \n",
        "        batch_loss = criterion(outputs, labels)\n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        batch_loss.backward() \n",
        "        optimizer.step() \n",
        "\n",
        "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "    # validation\n",
        "    if len(val_set) > 0:\n",
        "        model.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "        \n",
        "            for i, data in enumerate(val_loader):\n",
        "                val_last = val_acc\n",
        "                # print(i)\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                batch_loss = criterion(outputs, labels) \n",
        "                _, val_pred = torch.max(outputs, 1) \n",
        "            \n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "                val_loss += batch_loss.item()\n",
        "\n",
        "            # if (epoch % 10 == 0):\n",
        "              \n",
        "            #   torch.save(model.state_dict(), model_pathgd)\n",
        "            #   print('saving drive done')\n",
        "             \n",
        "\n",
        "\n",
        "            lastvalacc = val_loss/len(val_loader)\n",
        "\n",
        "\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "            ))\n",
        "            print( str(val_acc/len(val_set) - lastvalacc) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # if the model improves, save a checkpoint at this epoch\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                torch.save(model.state_dict(), model_pathgd)\n",
        "                print('saving drive done')\n",
        "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                # create model and load weights from checkpoint\n",
        "                model2 = Classifier().to(device)\n",
        "                model2.load_state_dict(torch.load(model_path))\n",
        "\n",
        "                predict = []\n",
        "                model2.eval() # set the model to evaluation mode\n",
        "                with torch.no_grad():\n",
        "                    for i, data in enumerate(test_loader):\n",
        "                      inputs = data\n",
        "                      inputs = inputs.to(device)\n",
        "                      outputs = model2(inputs)\n",
        "                      _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "\n",
        "                      for y in test_pred.cpu().numpy():\n",
        "                        predict.append(y)\n",
        "\n",
        "\n",
        "                with open('prediction.csv', 'w') as f:\n",
        "                  f.write('Id,Class\\n')\n",
        "                  for i, y in enumerate(predict):\n",
        "                    f.write('{},{}\\n'.format(i, y))\n",
        "                \n",
        "\n",
        "                print('write pred to workspace done')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                  # predtodrive = pd.read_csv(pred_path)               \n",
        "                  \n",
        "\n",
        "                  # uploaded = drive.CreateFile({'title': 'prediction.csv'})\n",
        "                  # uploaded.SetContentFile('prediction.csv')\n",
        "                  # uploaded.Upload()\n",
        "                  # torch.save(uploaded, pred_pathgd)\n",
        "                  # print('saving pred to drive done'+ '\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "    else:\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
        "        ))\n",
        "\n",
        "# if not validating, save the last epoch\n",
        "if len(val_set) == 0:\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print('saving model at last epoch')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[001/1000] Train Acc: 0.437546 Loss: 1.996455 | Val Acc: 0.582085 loss: 1.380612\n",
            "-0.7985266101489455\n",
            "saving drive done\n",
            "saving model with acc 0.582\n",
            "[002/1000] Train Acc: 0.532659 Loss: 1.595532 | Val Acc: 0.633023 loss: 1.209062\n",
            "-0.5760388653043979\n",
            "saving drive done\n",
            "saving model with acc 0.633\n",
            "[003/1000] Train Acc: 0.562592 Loss: 1.490784 | Val Acc: 0.650780 loss: 1.136345\n",
            "-0.48556505514215464\n",
            "saving drive done\n",
            "saving model with acc 0.651\n",
            "[004/1000] Train Acc: 0.580203 Loss: 1.428235 | Val Acc: 0.668073 loss: 1.080478\n",
            "-0.41240479085588755\n",
            "saving drive done\n",
            "saving model with acc 0.668\n",
            "[005/1000] Train Acc: 0.592093 Loss: 1.385055 | Val Acc: 0.676935 loss: 1.045828\n",
            "-0.3688924457490883\n",
            "saving drive done\n",
            "saving model with acc 0.677\n",
            "[006/1000] Train Acc: 0.601543 Loss: 1.352953 | Val Acc: 0.683586 loss: 1.018466\n",
            "-0.33488006685269267\n",
            "saving drive done\n",
            "saving model with acc 0.684\n",
            "[007/1000] Train Acc: 0.608487 Loss: 1.327785 | Val Acc: 0.690944 loss: 0.994208\n",
            "-0.3032637992331926\n",
            "saving drive done\n",
            "saving model with acc 0.691\n",
            "[008/1000] Train Acc: 0.614671 Loss: 1.304195 | Val Acc: 0.696871 loss: 0.975420\n",
            "-0.27854828885550564\n",
            "saving drive done\n",
            "saving model with acc 0.697\n",
            "[009/1000] Train Acc: 0.620724 Loss: 1.283569 | Val Acc: 0.701294 loss: 0.958785\n",
            "-0.2574910313700466\n",
            "saving drive done\n",
            "saving model with acc 0.701\n",
            "[010/1000] Train Acc: 0.624618 Loss: 1.268922 | Val Acc: 0.703620 loss: 0.944859\n",
            "-0.24123954785887702\n",
            "saving drive done\n",
            "saving model with acc 0.704\n",
            "[011/1000] Train Acc: 0.628674 Loss: 1.254771 | Val Acc: 0.708059 loss: 0.932569\n",
            "-0.22451010606268262\n",
            "saving drive done\n",
            "saving model with acc 0.708\n",
            "[012/1000] Train Acc: 0.633041 Loss: 1.238925 | Val Acc: 0.711067 loss: 0.918832\n",
            "-0.20776479841214512\n",
            "saving drive done\n",
            "saving model with acc 0.711\n",
            "[013/1000] Train Acc: 0.635866 Loss: 1.228279 | Val Acc: 0.714084 loss: 0.908703\n",
            "-0.19461903869708952\n",
            "saving drive done\n",
            "saving model with acc 0.714\n",
            "[014/1000] Train Acc: 0.638700 Loss: 1.218114 | Val Acc: 0.714897 loss: 0.901821\n",
            "-0.18692462962707923\n",
            "saving drive done\n",
            "saving model with acc 0.715\n",
            "[015/1000] Train Acc: 0.640682 Loss: 1.209937 | Val Acc: 0.717539 loss: 0.892984\n",
            "-0.17544449214262325\n",
            "saving drive done\n",
            "saving model with acc 0.718\n",
            "[016/1000] Train Acc: 0.644137 Loss: 1.198259 | Val Acc: 0.719572 loss: 0.884197\n",
            "-0.16462485978968555\n",
            "saving drive done\n",
            "saving model with acc 0.720\n",
            "[017/1000] Train Acc: 0.646182 Loss: 1.190669 | Val Acc: 0.721734 loss: 0.876659\n",
            "-0.15492432782955712\n",
            "saving drive done\n",
            "saving model with acc 0.722\n",
            "[018/1000] Train Acc: 0.648739 Loss: 1.182040 | Val Acc: 0.723190 loss: 0.870394\n",
            "-0.1472041798646968\n",
            "saving drive done\n",
            "saving model with acc 0.723\n",
            "[019/1000] Train Acc: 0.650766 Loss: 1.175567 | Val Acc: 0.725621 loss: 0.864226\n",
            "-0.13860511957651822\n",
            "saving drive done\n",
            "saving model with acc 0.726\n",
            "[020/1000] Train Acc: 0.651851 Loss: 1.168704 | Val Acc: 0.725930 loss: 0.857961\n",
            "-0.13203093683899192\n",
            "saving drive done\n",
            "saving model with acc 0.726\n",
            "[021/1000] Train Acc: 0.653671 Loss: 1.163694 | Val Acc: 0.727751 loss: 0.853039\n",
            "-0.12528809737722446\n",
            "saving drive done\n",
            "saving model with acc 0.728\n",
            "[022/1000] Train Acc: 0.655308 Loss: 1.157288 | Val Acc: 0.728686 loss: 0.849988\n",
            "-0.12130241165621813\n",
            "saving drive done\n",
            "saving model with acc 0.729\n",
            "[023/1000] Train Acc: 0.656645 Loss: 1.151570 | Val Acc: 0.730743 loss: 0.841650\n",
            "-0.1109074192186722\n",
            "saving drive done\n",
            "saving model with acc 0.731\n",
            "[024/1000] Train Acc: 0.657665 Loss: 1.147523 | Val Acc: 0.730792 loss: 0.840364\n",
            "-0.1095723636587288\n",
            "saving drive done\n",
            "saving model with acc 0.731\n",
            "[025/1000] Train Acc: 0.660003 Loss: 1.141357 | Val Acc: 0.732426 loss: 0.835613\n",
            "-0.10318691693843984\n",
            "saving drive done\n",
            "saving model with acc 0.732\n",
            "[026/1000] Train Acc: 0.660832 Loss: 1.137140 | Val Acc: 0.733914 loss: 0.830750\n",
            "-0.09683649372324399\n",
            "saving drive done\n",
            "saving model with acc 0.734\n",
            "[027/1000] Train Acc: 0.662422 Loss: 1.132683 | Val Acc: 0.734361 loss: 0.828523\n",
            "-0.09416230473416365\n",
            "saving drive done\n",
            "saving model with acc 0.734\n",
            "[028/1000] Train Acc: 0.662096 Loss: 1.129282 | Val Acc: 0.735052 loss: 0.825623\n",
            "-0.09057062375799185\n",
            "saving drive done\n",
            "saving model with acc 0.735\n",
            "[029/1000] Train Acc: 0.664072 Loss: 1.125670 | Val Acc: 0.735646 loss: 0.822550\n",
            "-0.08690412122305025\n",
            "saving drive done\n",
            "saving model with acc 0.736\n",
            "[030/1000] Train Acc: 0.664906 Loss: 1.122128 | Val Acc: 0.736483 loss: 0.820259\n",
            "-0.08377553721640696\n",
            "saving drive done\n",
            "saving model with acc 0.736\n",
            "[031/1000] Train Acc: 0.665108 Loss: 1.118856 | Val Acc: 0.737564 loss: 0.815511\n",
            "-0.07794690077724364\n",
            "saving drive done\n",
            "saving model with acc 0.738\n",
            "[032/1000] Train Acc: 0.666492 Loss: 1.115259 | Val Acc: 0.735906 loss: 0.818202\n",
            "-0.08229591870839092\n",
            "[033/1000] Train Acc: 0.667425 Loss: 1.112860 | Val Acc: 0.738922 loss: 0.809815\n",
            "-0.07089310851788122\n",
            "saving drive done\n",
            "saving model with acc 0.739\n",
            "[034/1000] Train Acc: 0.668380 Loss: 1.109401 | Val Acc: 0.740304 loss: 0.807205\n",
            "-0.06690015350441625\n",
            "saving drive done\n",
            "saving model with acc 0.740\n",
            "[035/1000] Train Acc: 0.668733 Loss: 1.107452 | Val Acc: 0.740491 loss: 0.805144\n",
            "-0.0646525255443623\n",
            "saving drive done\n",
            "saving model with acc 0.740\n",
            "[036/1000] Train Acc: 0.669618 Loss: 1.103935 | Val Acc: 0.740223 loss: 0.804793\n",
            "-0.06457007901210465\n",
            "[037/1000] Train Acc: 0.670543 Loss: 1.101617 | Val Acc: 0.741394 loss: 0.801799\n",
            "-0.0604052609813337\n",
            "saving drive done\n",
            "saving model with acc 0.741\n",
            "[038/1000] Train Acc: 0.670696 Loss: 1.100002 | Val Acc: 0.741622 loss: 0.800915\n",
            "-0.05929316742204349\n",
            "saving drive done\n",
            "saving model with acc 0.742\n",
            "[039/1000] Train Acc: 0.670909 Loss: 1.098900 | Val Acc: 0.741979 loss: 0.796969\n",
            "-0.05498952447677774\n",
            "saving drive done\n",
            "saving model with acc 0.742\n",
            "[040/1000] Train Acc: 0.671864 Loss: 1.095051 | Val Acc: 0.742573 loss: 0.795407\n",
            "-0.05283409941563921\n",
            "saving drive done\n",
            "saving model with acc 0.743\n",
            "[041/1000] Train Acc: 0.672535 Loss: 1.094001 | Val Acc: 0.743459 loss: 0.793663\n",
            "-0.050204235028225574\n",
            "saving drive done\n",
            "saving model with acc 0.743\n",
            "[042/1000] Train Acc: 0.672908 Loss: 1.092365 | Val Acc: 0.744451 loss: 0.791965\n",
            "-0.04751363571377343\n",
            "saving drive done\n",
            "saving model with acc 0.744\n",
            "[043/1000] Train Acc: 0.673629 Loss: 1.088669 | Val Acc: 0.744817 loss: 0.789516\n",
            "-0.04469898336105671\n",
            "saving drive done\n",
            "saving model with acc 0.745\n",
            "[044/1000] Train Acc: 0.674052 Loss: 1.089015 | Val Acc: 0.743695 loss: 0.789641\n",
            "-0.0459457177983873\n",
            "[045/1000] Train Acc: 0.674388 Loss: 1.086164 | Val Acc: 0.745110 loss: 0.785021\n",
            "-0.03991140898460477\n",
            "saving drive done\n",
            "saving model with acc 0.745\n",
            "[046/1000] Train Acc: 0.675096 Loss: 1.084822 | Val Acc: 0.746540 loss: 0.784428\n",
            "-0.03788737730016545\n",
            "saving drive done\n",
            "saving model with acc 0.747\n",
            "[047/1000] Train Acc: 0.674913 Loss: 1.083653 | Val Acc: 0.744939 loss: 0.785766\n",
            "-0.04082737523333746\n",
            "[048/1000] Train Acc: 0.675073 Loss: 1.082081 | Val Acc: 0.746606 loss: 0.780104\n",
            "-0.033497979378794396\n",
            "saving drive done\n",
            "saving model with acc 0.747\n",
            "[049/1000] Train Acc: 0.675319 Loss: 1.080335 | Val Acc: 0.746101 loss: 0.782157\n",
            "-0.03605581178622408\n",
            "[050/1000] Train Acc: 0.676594 Loss: 1.078921 | Val Acc: 0.746793 loss: 0.780116\n",
            "-0.03332386471724014\n",
            "saving drive done\n",
            "saving model with acc 0.747\n",
            "[051/1000] Train Acc: 0.676767 Loss: 1.077475 | Val Acc: 0.747671 loss: 0.776944\n",
            "-0.02927375075645655\n",
            "saving drive done\n",
            "saving model with acc 0.748\n",
            "[052/1000] Train Acc: 0.677121 Loss: 1.075203 | Val Acc: 0.747077 loss: 0.777676\n",
            "-0.03059904080165754\n",
            "[053/1000] Train Acc: 0.677808 Loss: 1.074466 | Val Acc: 0.747858 loss: 0.776007\n",
            "-0.028149534761966466\n",
            "saving drive done\n",
            "saving model with acc 0.748\n",
            "[054/1000] Train Acc: 0.677747 Loss: 1.072852 | Val Acc: 0.748402 loss: 0.774927\n",
            "-0.02652444479310334\n",
            "saving drive done\n",
            "saving model with acc 0.748\n",
            "[055/1000] Train Acc: 0.678093 Loss: 1.072606 | Val Acc: 0.747752 loss: 0.774055\n",
            "-0.02630308727077102\n",
            "[056/1000] Train Acc: 0.678832 Loss: 1.070449 | Val Acc: 0.748589 loss: 0.772403\n",
            "-0.023813418632339767\n",
            "saving drive done\n",
            "saving model with acc 0.749\n",
            "[057/1000] Train Acc: 0.678895 Loss: 1.069238 | Val Acc: 0.748638 loss: 0.773001\n",
            "-0.024362570662235905\n",
            "saving drive done\n",
            "saving model with acc 0.749\n",
            "[058/1000] Train Acc: 0.678646 Loss: 1.069313 | Val Acc: 0.749183 loss: 0.769673\n",
            "-0.020490199308710766\n",
            "saving drive done\n",
            "saving model with acc 0.749\n",
            "[059/1000] Train Acc: 0.679456 Loss: 1.067825 | Val Acc: 0.750370 loss: 0.767765\n",
            "-0.017395110456414287\n",
            "saving drive done\n",
            "saving model with acc 0.750\n",
            "[060/1000] Train Acc: 0.679179 Loss: 1.067198 | Val Acc: 0.749963 loss: 0.766645\n",
            "-0.01668128771267441\n",
            "[061/1000] Train Acc: 0.679857 Loss: 1.065309 | Val Acc: 0.749671 loss: 0.771085\n",
            "-0.021414723529490254\n",
            "[062/1000] Train Acc: 0.680034 Loss: 1.065200 | Val Acc: 0.750451 loss: 0.765262\n",
            "-0.014811135835056777\n",
            "saving drive done\n",
            "saving model with acc 0.750\n",
            "[063/1000] Train Acc: 0.680418 Loss: 1.064120 | Val Acc: 0.750346 loss: 0.767702\n",
            "-0.017356480300072752\n",
            "[064/1000] Train Acc: 0.680446 Loss: 1.062644 | Val Acc: 0.751476 loss: 0.764503\n",
            "-0.013027762469727922\n",
            "saving drive done\n",
            "saving model with acc 0.751\n",
            "[065/1000] Train Acc: 0.681375 Loss: 1.061168 | Val Acc: 0.751655 loss: 0.763888\n",
            "-0.012233479813500425\n",
            "saving drive done\n",
            "saving model with acc 0.752\n",
            "[066/1000] Train Acc: 0.681097 Loss: 1.060470 | Val Acc: 0.751736 loss: 0.762603\n",
            "-0.010867366677818069\n",
            "saving drive done\n",
            "saving model with acc 0.752\n",
            "[067/1000] Train Acc: 0.681730 Loss: 1.059510 | Val Acc: 0.751606 loss: 0.764643\n",
            "-0.013037042403589938\n",
            "[068/1000] Train Acc: 0.682228 Loss: 1.057023 | Val Acc: 0.752378 loss: 0.759266\n",
            "-0.006887423568670337\n",
            "saving drive done\n",
            "saving model with acc 0.752\n",
            "[069/1000] Train Acc: 0.681946 Loss: 1.057314 | Val Acc: 0.751354 loss: 0.761251\n",
            "-0.009896848485538956\n",
            "[070/1000] Train Acc: 0.682445 Loss: 1.057205 | Val Acc: 0.753256 loss: 0.757768\n",
            "-0.0045112817299549635\n",
            "saving drive done\n",
            "saving model with acc 0.753\n",
            "[071/1000] Train Acc: 0.681979 Loss: 1.057331 | Val Acc: 0.752679 loss: 0.759004\n",
            "-0.006324776911051266\n",
            "[072/1000] Train Acc: 0.682569 Loss: 1.055785 | Val Acc: 0.752338 loss: 0.759289\n",
            "-0.006951279222624729\n",
            "[073/1000] Train Acc: 0.682591 Loss: 1.054619 | Val Acc: 0.752598 loss: 0.758535\n",
            "-0.005937530159075499\n",
            "[074/1000] Train Acc: 0.682677 Loss: 1.053831 | Val Acc: 0.754102 loss: 0.755218\n",
            "-0.001116384347601862\n",
            "saving drive done\n",
            "saving model with acc 0.754\n",
            "[075/1000] Train Acc: 0.682877 Loss: 1.053422 | Val Acc: 0.752573 loss: 0.758801\n",
            "-0.006227998277771207\n",
            "[076/1000] Train Acc: 0.683526 Loss: 1.052345 | Val Acc: 0.753346 loss: 0.756399\n",
            "-0.0030530369512676847\n",
            "[077/1000] Train Acc: 0.683050 Loss: 1.053332 | Val Acc: 0.753313 loss: 0.755653\n",
            "-0.0023401260208371077\n",
            "[078/1000] Train Acc: 0.683662 Loss: 1.050480 | Val Acc: 0.753329 loss: 0.752914\n",
            "0.00041511092896795443\n",
            "[079/1000] Train Acc: 0.684032 Loss: 1.050690 | Val Acc: 0.754923 loss: 0.751974\n",
            "0.0029492052850910166\n",
            "saving drive done\n",
            "saving model with acc 0.755\n",
            "[080/1000] Train Acc: 0.684170 Loss: 1.049793 | Val Acc: 0.753557 loss: 0.754987\n",
            "-0.0014303209007231477\n",
            "[081/1000] Train Acc: 0.683903 Loss: 1.049111 | Val Acc: 0.754370 loss: 0.752388\n",
            "0.0019820956252836197\n",
            "[082/1000] Train Acc: 0.683929 Loss: 1.049478 | Val Acc: 0.754167 loss: 0.752638\n",
            "0.0015291675565983764\n",
            "[083/1000] Train Acc: 0.683889 Loss: 1.049386 | Val Acc: 0.755004 loss: 0.750991\n",
            "0.004013631788818639\n",
            "saving drive done\n",
            "saving model with acc 0.755\n",
            "[084/1000] Train Acc: 0.684792 Loss: 1.046783 | Val Acc: 0.755500 loss: 0.749999\n",
            "0.005501682050410572\n",
            "saving drive done\n",
            "saving model with acc 0.756\n",
            "[085/1000] Train Acc: 0.684074 Loss: 1.047558 | Val Acc: 0.754907 loss: 0.749765\n",
            "0.005141893239993034\n",
            "[086/1000] Train Acc: 0.684981 Loss: 1.046236 | Val Acc: 0.756330 loss: 0.747281\n",
            "0.009048954942404874\n",
            "saving drive done\n",
            "saving model with acc 0.756\n",
            "[087/1000] Train Acc: 0.684982 Loss: 1.045917 | Val Acc: 0.752996 loss: 0.752552\n",
            "0.0004436018464040181\n",
            "[088/1000] Train Acc: 0.685137 Loss: 1.046168 | Val Acc: 0.754151 loss: 0.750126\n",
            "0.004024761858015369\n",
            "[089/1000] Train Acc: 0.685778 Loss: 1.044490 | Val Acc: 0.754435 loss: 0.749777\n",
            "0.004658554427703354\n",
            "[090/1000] Train Acc: 0.685704 Loss: 1.043265 | Val Acc: 0.755817 loss: 0.747564\n",
            "0.00825361674506686\n",
            "[091/1000] Train Acc: 0.686225 Loss: 1.043515 | Val Acc: 0.755427 loss: 0.748383\n",
            "0.007044195735924741\n",
            "[092/1000] Train Acc: 0.686048 Loss: 1.042865 | Val Acc: 0.754647 loss: 0.748252\n",
            "0.00639437082475891\n",
            "[093/1000] Train Acc: 0.685318 Loss: 1.044129 | Val Acc: 0.756695 loss: 0.745256\n",
            "0.011439470334712154\n",
            "saving drive done\n",
            "saving model with acc 0.757\n",
            "[094/1000] Train Acc: 0.685784 Loss: 1.041502 | Val Acc: 0.755907 loss: 0.745825\n",
            "0.01008217849439319\n",
            "[095/1000] Train Acc: 0.686101 Loss: 1.042863 | Val Acc: 0.756232 loss: 0.745034\n",
            "0.01119810963006529\n",
            "[096/1000] Train Acc: 0.685965 Loss: 1.042349 | Val Acc: 0.755891 loss: 0.743060\n",
            "0.012830751093563242\n",
            "[097/1000] Train Acc: 0.686358 Loss: 1.041312 | Val Acc: 0.756029 loss: 0.744306\n",
            "0.011723090544843218\n",
            "[098/1000] Train Acc: 0.686091 Loss: 1.040084 | Val Acc: 0.755736 loss: 0.743327\n",
            "0.012408611831586036\n",
            "[099/1000] Train Acc: 0.686317 Loss: 1.039681 | Val Acc: 0.756240 loss: 0.743178\n",
            "0.01306229700559558\n",
            "[100/1000] Train Acc: 0.687002 Loss: 1.039221 | Val Acc: 0.754525 loss: 0.743883\n",
            "0.01064121769998716\n",
            "[101/1000] Train Acc: 0.687136 Loss: 1.038569 | Val Acc: 0.755151 loss: 0.744248\n",
            "0.010902693513053396\n",
            "[102/1000] Train Acc: 0.686983 Loss: 1.039290 | Val Acc: 0.757134 loss: 0.740938\n",
            "0.016196744626963078\n",
            "saving drive done\n",
            "saving model with acc 0.757\n",
            "[103/1000] Train Acc: 0.686832 Loss: 1.039694 | Val Acc: 0.757004 loss: 0.741476\n",
            "0.015528354737170735\n",
            "[104/1000] Train Acc: 0.687309 Loss: 1.037366 | Val Acc: 0.756972 loss: 0.740069\n",
            "0.016902490424384964\n",
            "[105/1000] Train Acc: 0.687274 Loss: 1.036615 | Val Acc: 0.756395 loss: 0.741376\n",
            "0.015018537852635294\n",
            "[106/1000] Train Acc: 0.686875 Loss: 1.037251 | Val Acc: 0.758663 loss: 0.738686\n",
            "0.01997709206283127\n",
            "saving drive done\n",
            "saving model with acc 0.759\n",
            "[107/1000] Train Acc: 0.687113 Loss: 1.038793 | Val Acc: 0.757948 loss: 0.740782\n",
            "0.01716589102211452\n",
            "[108/1000] Train Acc: 0.687373 Loss: 1.037568 | Val Acc: 0.757533 loss: 0.739199\n",
            "0.01833399326302787\n",
            "[109/1000] Train Acc: 0.687788 Loss: 1.036137 | Val Acc: 0.757208 loss: 0.741015\n",
            "0.01619222359525696\n",
            "[110/1000] Train Acc: 0.687786 Loss: 1.036571 | Val Acc: 0.758257 loss: 0.738721\n",
            "0.019535779068399983\n",
            "[111/1000] Train Acc: 0.687443 Loss: 1.036292 | Val Acc: 0.756858 loss: 0.739952\n",
            "0.016906476287693595\n",
            "[112/1000] Train Acc: 0.688005 Loss: 1.035184 | Val Acc: 0.757419 loss: 0.739148\n",
            "0.018271519026689775\n",
            "[113/1000] Train Acc: 0.689027 Loss: 1.032853 | Val Acc: 0.758517 loss: 0.738335\n",
            "0.020181344619920494\n",
            "[114/1000] Train Acc: 0.688056 Loss: 1.033819 | Val Acc: 0.758126 loss: 0.737290\n",
            "0.02083637904514346\n",
            "[115/1000] Train Acc: 0.688596 Loss: 1.034270 | Val Acc: 0.757004 loss: 0.738783\n",
            "0.018221785755984543\n",
            "[116/1000] Train Acc: 0.688908 Loss: 1.032591 | Val Acc: 0.758354 loss: 0.735495\n",
            "0.02285857888151166\n",
            "[117/1000] Train Acc: 0.688833 Loss: 1.033358 | Val Acc: 0.758744 loss: 0.736711\n",
            "0.022033297550861253\n",
            "saving drive done\n",
            "saving model with acc 0.759\n",
            "[118/1000] Train Acc: 0.688432 Loss: 1.032698 | Val Acc: 0.758240 loss: 0.739122\n",
            "0.01911794790681487\n",
            "[119/1000] Train Acc: 0.688425 Loss: 1.032099 | Val Acc: 0.758013 loss: 0.736712\n",
            "0.021300517418187948\n",
            "[120/1000] Train Acc: 0.688690 Loss: 1.032792 | Val Acc: 0.758606 loss: 0.736826\n",
            "0.02177988022104782\n",
            "[121/1000] Train Acc: 0.688513 Loss: 1.032803 | Val Acc: 0.758492 loss: 0.737321\n",
            "0.021171307696227992\n",
            "[122/1000] Train Acc: 0.688918 Loss: 1.031263 | Val Acc: 0.757069 loss: 0.737248\n",
            "0.019821447350238608\n",
            "[123/1000] Train Acc: 0.688751 Loss: 1.032423 | Val Acc: 0.757679 loss: 0.734593\n",
            "0.02308591566882734\n",
            "[124/1000] Train Acc: 0.688705 Loss: 1.030822 | Val Acc: 0.758874 loss: 0.732457\n",
            "0.026417861523680974\n",
            "saving drive done\n",
            "saving model with acc 0.759\n",
            "[125/1000] Train Acc: 0.689398 Loss: 1.029689 | Val Acc: 0.759687 loss: 0.731814\n",
            "0.027873653723989755\n",
            "saving drive done\n",
            "saving model with acc 0.760\n",
            "[126/1000] Train Acc: 0.689184 Loss: 1.030360 | Val Acc: 0.757663 loss: 0.737064\n",
            "0.02059922230939748\n",
            "[127/1000] Train Acc: 0.689292 Loss: 1.030280 | Val Acc: 0.759135 loss: 0.733056\n",
            "0.026078251461736257\n",
            "[128/1000] Train Acc: 0.688968 Loss: 1.030145 | Val Acc: 0.758907 loss: 0.733788\n",
            "0.02511922161258895\n",
            "[129/1000] Train Acc: 0.689346 Loss: 1.030620 | Val Acc: 0.759696 loss: 0.733312\n",
            "0.02638376237441853\n",
            "saving drive done\n",
            "saving model with acc 0.760\n",
            "[130/1000] Train Acc: 0.689820 Loss: 1.028662 | Val Acc: 0.758354 loss: 0.733938\n",
            "0.024415933207682317\n",
            "[131/1000] Train Acc: 0.689721 Loss: 1.029604 | Val Acc: 0.759704 loss: 0.732894\n",
            "0.026809762408568916\n",
            "saving drive done\n",
            "saving model with acc 0.760\n",
            "[132/1000] Train Acc: 0.689247 Loss: 1.029254 | Val Acc: 0.759411 loss: 0.731720\n",
            "0.02769123580645516\n",
            "[133/1000] Train Acc: 0.689923 Loss: 1.027392 | Val Acc: 0.758549 loss: 0.732944\n",
            "0.025605233275018513\n",
            "[134/1000] Train Acc: 0.689773 Loss: 1.027462 | Val Acc: 0.758704 loss: 0.730579\n",
            "0.028124885863780036\n",
            "[135/1000] Train Acc: 0.689735 Loss: 1.027593 | Val Acc: 0.759175 loss: 0.732657\n",
            "0.026518625392339512\n",
            "[136/1000] Train Acc: 0.690134 Loss: 1.027057 | Val Acc: 0.758086 loss: 0.733870\n",
            "0.024215555070512873\n",
            "[137/1000] Train Acc: 0.690806 Loss: 1.026933 | Val Acc: 0.758687 loss: 0.732310\n",
            "0.02637704993645973\n",
            "[138/1000] Train Acc: 0.690006 Loss: 1.026844 | Val Acc: 0.759029 loss: 0.732239\n",
            "0.026789762308152776\n",
            "[139/1000] Train Acc: 0.690447 Loss: 1.027255 | Val Acc: 0.759151 loss: 0.732276\n",
            "0.026875249429937687\n",
            "[140/1000] Train Acc: 0.690244 Loss: 1.028081 | Val Acc: 0.760143 loss: 0.730296\n",
            "0.029847090256300723\n",
            "saving drive done\n",
            "saving model with acc 0.760\n",
            "[141/1000] Train Acc: 0.690497 Loss: 1.025389 | Val Acc: 0.759338 loss: 0.732848\n",
            "0.026490170807930147\n",
            "[142/1000] Train Acc: 0.690096 Loss: 1.026108 | Val Acc: 0.760549 loss: 0.729774\n",
            "0.030775700927175187\n",
            "saving drive done\n",
            "saving model with acc 0.761\n",
            "[143/1000] Train Acc: 0.690489 Loss: 1.027037 | Val Acc: 0.760452 loss: 0.728928\n",
            "0.03152376886961206\n",
            "[144/1000] Train Acc: 0.690577 Loss: 1.024896 | Val Acc: 0.759866 loss: 0.730540\n",
            "0.02932640052122537\n",
            "[145/1000] Train Acc: 0.689885 Loss: 1.026136 | Val Acc: 0.760541 loss: 0.727055\n",
            "0.03348640603378206\n",
            "[146/1000] Train Acc: 0.690428 Loss: 1.024803 | Val Acc: 0.759435 loss: 0.727889\n",
            "0.03154672213125875\n",
            "[147/1000] Train Acc: 0.690490 Loss: 1.025346 | Val Acc: 0.761021 loss: 0.728764\n",
            "0.03225708322039211\n",
            "saving drive done\n",
            "saving model with acc 0.761\n",
            "[148/1000] Train Acc: 0.690552 Loss: 1.024846 | Val Acc: 0.759354 loss: 0.731682\n",
            "0.027671939436997084\n",
            "[149/1000] Train Acc: 0.690425 Loss: 1.025024 | Val Acc: 0.760045 loss: 0.728519\n",
            "0.03152616031358413\n",
            "[150/1000] Train Acc: 0.690232 Loss: 1.024628 | Val Acc: 0.760200 loss: 0.727373\n",
            "0.032827082012660935\n",
            "[151/1000] Train Acc: 0.690716 Loss: 1.025871 | Val Acc: 0.760728 loss: 0.728091\n",
            "0.03263672088438396\n",
            "[152/1000] Train Acc: 0.690592 Loss: 1.024583 | Val Acc: 0.759183 loss: 0.729693\n",
            "0.029490853810104634\n",
            "[153/1000] Train Acc: 0.690720 Loss: 1.024646 | Val Acc: 0.760330 loss: 0.729665\n",
            "0.030664711152109225\n",
            "[154/1000] Train Acc: 0.690488 Loss: 1.024835 | Val Acc: 0.759940 loss: 0.728902\n",
            "0.03103706725426858\n",
            "[155/1000] Train Acc: 0.690721 Loss: 1.024847 | Val Acc: 0.760614 loss: 0.727721\n",
            "0.032893355426914184\n",
            "[156/1000] Train Acc: 0.690857 Loss: 1.023569 | Val Acc: 0.759387 loss: 0.729061\n",
            "0.03032612856897554\n",
            "[157/1000] Train Acc: 0.690687 Loss: 1.023741 | Val Acc: 0.760517 loss: 0.726491\n",
            "0.03402599849790633\n",
            "[158/1000] Train Acc: 0.691017 Loss: 1.023652 | Val Acc: 0.760305 loss: 0.728243\n",
            "0.032062858611390355\n",
            "[159/1000] Train Acc: 0.691127 Loss: 1.024390 | Val Acc: 0.760078 loss: 0.728267\n",
            "0.03181033419848123\n",
            "[160/1000] Train Acc: 0.690303 Loss: 1.023850 | Val Acc: 0.759631 loss: 0.728746\n",
            "0.03088453610496522\n",
            "[161/1000] Train Acc: 0.691266 Loss: 1.022349 | Val Acc: 0.760029 loss: 0.727584\n",
            "0.0324450789344064\n",
            "[162/1000] Train Acc: 0.691448 Loss: 1.021137 | Val Acc: 0.759322 loss: 0.728691\n",
            "0.03063087365795325\n",
            "[163/1000] Train Acc: 0.691641 Loss: 1.021498 | Val Acc: 0.760590 loss: 0.726929\n",
            "0.0336606215941313\n",
            "[164/1000] Train Acc: 0.691620 Loss: 1.021541 | Val Acc: 0.760452 loss: 0.726788\n",
            "0.03366382629577003\n",
            "[165/1000] Train Acc: 0.691889 Loss: 1.020636 | Val Acc: 0.760744 loss: 0.726441\n",
            "0.03430320485500349\n",
            "[166/1000] Train Acc: 0.691921 Loss: 1.020919 | Val Acc: 0.761062 loss: 0.726828\n",
            "0.034233419467074255\n",
            "saving drive done\n",
            "saving model with acc 0.761\n",
            "[167/1000] Train Acc: 0.691184 Loss: 1.021958 | Val Acc: 0.760915 loss: 0.726149\n",
            "0.03476652432100835\n",
            "[168/1000] Train Acc: 0.691573 Loss: 1.020749 | Val Acc: 0.759931 loss: 0.726937\n",
            "0.03299444844534749\n",
            "[169/1000] Train Acc: 0.691942 Loss: 1.020399 | Val Acc: 0.761427 loss: 0.725600\n",
            "0.03582780598935564\n",
            "saving drive done\n",
            "saving model with acc 0.761\n",
            "[170/1000] Train Acc: 0.692153 Loss: 1.019873 | Val Acc: 0.760663 loss: 0.725294\n",
            "0.03536956434762761\n",
            "[171/1000] Train Acc: 0.692045 Loss: 1.020156 | Val Acc: 0.760005 loss: 0.728288\n",
            "0.0317161089905329\n",
            "[172/1000] Train Acc: 0.692191 Loss: 1.020527 | Val Acc: 0.762476 loss: 0.722669\n",
            "0.0398067724652702\n",
            "saving drive done\n",
            "saving model with acc 0.762\n",
            "[173/1000] Train Acc: 0.691949 Loss: 1.019325 | Val Acc: 0.761671 loss: 0.722782\n",
            "0.038888945637501005\n",
            "[174/1000] Train Acc: 0.691952 Loss: 1.020474 | Val Acc: 0.760135 loss: 0.724635\n",
            "0.03549930793984046\n",
            "[175/1000] Train Acc: 0.691762 Loss: 1.019731 | Val Acc: 0.761484 loss: 0.724360\n",
            "0.03712456451562118\n",
            "[176/1000] Train Acc: 0.691577 Loss: 1.019886 | Val Acc: 0.761362 loss: 0.724588\n",
            "0.0367745221295418\n",
            "[177/1000] Train Acc: 0.691835 Loss: 1.020331 | Val Acc: 0.760972 loss: 0.725492\n",
            "0.035480088760082684\n",
            "[178/1000] Train Acc: 0.692435 Loss: 1.019295 | Val Acc: 0.761151 loss: 0.724028\n",
            "0.03712289994103446\n",
            "[179/1000] Train Acc: 0.691842 Loss: 1.019441 | Val Acc: 0.760777 loss: 0.725200\n",
            "0.03557715844873188\n",
            "[180/1000] Train Acc: 0.691506 Loss: 1.019694 | Val Acc: 0.761086 loss: 0.724045\n",
            "0.03704058065642202\n",
            "[181/1000] Train Acc: 0.692102 Loss: 1.019161 | Val Acc: 0.760297 loss: 0.725302\n",
            "0.03499511364957775\n",
            "[182/1000] Train Acc: 0.691698 Loss: 1.020729 | Val Acc: 0.761005 loss: 0.723792\n",
            "0.03721226910047093\n",
            "[183/1000] Train Acc: 0.692398 Loss: 1.018183 | Val Acc: 0.761037 loss: 0.723200\n",
            "0.037836636931555145\n",
            "[184/1000] Train Acc: 0.691951 Loss: 1.019249 | Val Acc: 0.761883 loss: 0.723402\n",
            "0.038480963908118615\n",
            "[185/1000] Train Acc: 0.692040 Loss: 1.018793 | Val Acc: 0.760948 loss: 0.723723\n",
            "0.0372250872774863\n",
            "[186/1000] Train Acc: 0.692153 Loss: 1.018406 | Val Acc: 0.760964 loss: 0.723675\n",
            "0.037289366413563285\n",
            "[187/1000] Train Acc: 0.691775 Loss: 1.018983 | Val Acc: 0.761574 loss: 0.723321\n",
            "0.038253233212931725\n",
            "[188/1000] Train Acc: 0.692561 Loss: 1.018661 | Val Acc: 0.760622 loss: 0.723680\n",
            "0.03694251586595221\n",
            "[189/1000] Train Acc: 0.692560 Loss: 1.018105 | Val Acc: 0.762265 loss: 0.721520\n",
            "0.04074445960667206\n",
            "[190/1000] Train Acc: 0.692505 Loss: 1.018354 | Val Acc: 0.761460 loss: 0.723112\n",
            "0.038347691222018754\n",
            "[191/1000] Train Acc: 0.692584 Loss: 1.017933 | Val Acc: 0.763102 loss: 0.719950\n",
            "0.04315207726645043\n",
            "saving drive done\n",
            "saving model with acc 0.763\n",
            "[192/1000] Train Acc: 0.692785 Loss: 1.016869 | Val Acc: 0.762094 loss: 0.722197\n",
            "0.03989698025780375\n",
            "[193/1000] Train Acc: 0.692521 Loss: 1.016596 | Val Acc: 0.760452 loss: 0.724070\n",
            "0.036381406742152955\n",
            "[194/1000] Train Acc: 0.692731 Loss: 1.016453 | Val Acc: 0.763322 loss: 0.720005\n",
            "0.04331677295865766\n",
            "saving drive done\n",
            "saving model with acc 0.763\n",
            "[195/1000] Train Acc: 0.693198 Loss: 1.016707 | Val Acc: 0.761858 loss: 0.721960\n",
            "0.03989837728465828\n",
            "[196/1000] Train Acc: 0.692960 Loss: 1.016682 | Val Acc: 0.760883 loss: 0.723856\n",
            "0.03702692878870595\n",
            "[197/1000] Train Acc: 0.692504 Loss: 1.016750 | Val Acc: 0.761980 loss: 0.723306\n",
            "0.038674350312268846\n",
            "[198/1000] Train Acc: 0.692211 Loss: 1.017343 | Val Acc: 0.761712 loss: 0.722415\n",
            "0.03929741543087273\n",
            "[199/1000] Train Acc: 0.693064 Loss: 1.017516 | Val Acc: 0.761468 loss: 0.723078\n",
            "0.03839033424302496\n",
            "[200/1000] Train Acc: 0.692537 Loss: 1.017028 | Val Acc: 0.762240 loss: 0.720884\n",
            "0.04135628766668542\n",
            "[201/1000] Train Acc: 0.693165 Loss: 1.016206 | Val Acc: 0.761216 loss: 0.724437\n",
            "0.036778625730068515\n",
            "[202/1000] Train Acc: 0.693053 Loss: 1.017225 | Val Acc: 0.761988 loss: 0.720795\n",
            "0.04119314565058585\n",
            "[203/1000] Train Acc: 0.693240 Loss: 1.015397 | Val Acc: 0.761891 loss: 0.721816\n",
            "0.040074791786888775\n",
            "[204/1000] Train Acc: 0.692262 Loss: 1.016649 | Val Acc: 0.763216 loss: 0.719419\n",
            "0.04379692842483762\n",
            "[205/1000] Train Acc: 0.693055 Loss: 1.015801 | Val Acc: 0.761452 loss: 0.722378\n",
            "0.039073556230190376\n",
            "[206/1000] Train Acc: 0.693348 Loss: 1.015351 | Val Acc: 0.762411 loss: 0.719862\n",
            "0.04254947269531539\n",
            "[207/1000] Train Acc: 0.693683 Loss: 1.015581 | Val Acc: 0.762240 loss: 0.720479\n",
            "0.04176183505294795\n",
            "[208/1000] Train Acc: 0.693146 Loss: 1.015751 | Val Acc: 0.762436 loss: 0.720124\n",
            "0.04231205978871233\n",
            "[209/1000] Train Acc: 0.692998 Loss: 1.016181 | Val Acc: 0.763265 loss: 0.720978\n",
            "0.04228645305808454\n",
            "[210/1000] Train Acc: 0.693559 Loss: 1.014988 | Val Acc: 0.763013 loss: 0.718893\n",
            "0.044120264984896296\n",
            "[211/1000] Train Acc: 0.693306 Loss: 1.016038 | Val Acc: 0.762598 loss: 0.721026\n",
            "0.04157235644981705\n",
            "[212/1000] Train Acc: 0.693715 Loss: 1.015116 | Val Acc: 0.762436 loss: 0.719205\n",
            "0.04323026061884627\n",
            "[213/1000] Train Acc: 0.693304 Loss: 1.015488 | Val Acc: 0.762647 loss: 0.718657\n",
            "0.043990153400159326\n",
            "[214/1000] Train Acc: 0.693605 Loss: 1.014495 | Val Acc: 0.763078 loss: 0.718737\n",
            "0.044340997981769825\n",
            "[215/1000] Train Acc: 0.693466 Loss: 1.015678 | Val Acc: 0.763574 loss: 0.717634\n",
            "0.045940250933052096\n",
            "saving drive done\n",
            "saving model with acc 0.764\n",
            "[216/1000] Train Acc: 0.693288 Loss: 1.015992 | Val Acc: 0.761671 loss: 0.720622\n",
            "0.041049571512012606\n",
            "[217/1000] Train Acc: 0.693197 Loss: 1.015336 | Val Acc: 0.763655 loss: 0.717315\n",
            "0.04633968736251337\n",
            "saving drive done\n",
            "saving model with acc 0.764\n",
            "[218/1000] Train Acc: 0.693529 Loss: 1.014746 | Val Acc: 0.763899 loss: 0.717703\n",
            "0.04619635269718647\n",
            "saving drive done\n",
            "saving model with acc 0.764\n",
            "[219/1000] Train Acc: 0.693188 Loss: 1.015127 | Val Acc: 0.763021 loss: 0.718518\n",
            "0.04450270831913883\n",
            "[220/1000] Train Acc: 0.693675 Loss: 1.013943 | Val Acc: 0.762940 loss: 0.720522\n",
            "0.042417171579250956\n",
            "[221/1000] Train Acc: 0.693682 Loss: 1.015005 | Val Acc: 0.761484 loss: 0.720635\n",
            "0.04084910951372811\n",
            "[222/1000] Train Acc: 0.693541 Loss: 1.014791 | Val Acc: 0.761476 loss: 0.720901\n",
            "0.0405756555984923\n",
            "[223/1000] Train Acc: 0.693320 Loss: 1.015741 | Val Acc: 0.764241 loss: 0.716547\n",
            "0.0476932091067932\n",
            "saving drive done\n",
            "saving model with acc 0.764\n",
            "[224/1000] Train Acc: 0.693762 Loss: 1.014402 | Val Acc: 0.763574 loss: 0.718972\n",
            "0.04460139637979843\n",
            "[225/1000] Train Acc: 0.693317 Loss: 1.014816 | Val Acc: 0.763127 loss: 0.718901\n",
            "0.04422533686787011\n",
            "[226/1000] Train Acc: 0.693515 Loss: 1.014332 | Val Acc: 0.762631 loss: 0.718198\n",
            "0.0444328720509688\n",
            "[227/1000] Train Acc: 0.693661 Loss: 1.014187 | Val Acc: 0.764696 loss: 0.718106\n",
            "0.046589417356578955\n",
            "saving drive done\n",
            "saving model with acc 0.765\n",
            "[228/1000] Train Acc: 0.693911 Loss: 1.013457 | Val Acc: 0.762964 loss: 0.718266\n",
            "0.04469822868860018\n",
            "[229/1000] Train Acc: 0.694594 Loss: 1.013100 | Val Acc: 0.762753 loss: 0.718161\n",
            "0.04459155682637683\n",
            "[230/1000] Train Acc: 0.693719 Loss: 1.012875 | Val Acc: 0.763452 loss: 0.718672\n",
            "0.04478007762516678\n",
            "[231/1000] Train Acc: 0.694366 Loss: 1.012118 | Val Acc: 0.763460 loss: 0.716155\n",
            "0.047305364296972297\n",
            "[232/1000] Train Acc: 0.693847 Loss: 1.012609 | Val Acc: 0.763200 loss: 0.717557\n",
            "0.045642700967984284\n",
            "[233/1000] Train Acc: 0.693421 Loss: 1.013170 | Val Acc: 0.762883 loss: 0.717113\n",
            "0.045770029503783616\n",
            "[234/1000] Train Acc: 0.693928 Loss: 1.013541 | Val Acc: 0.762257 loss: 0.718861\n",
            "0.0433954297620891\n",
            "[235/1000] Train Acc: 0.694268 Loss: 1.013854 | Val Acc: 0.761826 loss: 0.719065\n",
            "0.042760287258685414\n",
            "[236/1000] Train Acc: 0.694034 Loss: 1.012999 | Val Acc: 0.763427 loss: 0.715582\n",
            "0.047845975111569516\n",
            "[237/1000] Train Acc: 0.694158 Loss: 1.012509 | Val Acc: 0.763696 loss: 0.717451\n",
            "0.046245107280222686\n",
            "[238/1000] Train Acc: 0.694107 Loss: 1.011619 | Val Acc: 0.763411 loss: 0.717413\n",
            "0.04599789027757861\n",
            "[239/1000] Train Acc: 0.693707 Loss: 1.012800 | Val Acc: 0.764281 loss: 0.715304\n",
            "0.04897753964357132\n",
            "[240/1000] Train Acc: 0.694269 Loss: 1.012621 | Val Acc: 0.763094 loss: 0.718622\n",
            "0.044472097655987586\n",
            "[241/1000] Train Acc: 0.694050 Loss: 1.012992 | Val Acc: 0.763696 loss: 0.717276\n",
            "0.046419919271472376\n",
            "[242/1000] Train Acc: 0.694257 Loss: 1.011804 | Val Acc: 0.762118 loss: 0.719275\n",
            "0.04284347912832487\n",
            "[243/1000] Train Acc: 0.694386 Loss: 1.011633 | Val Acc: 0.762663 loss: 0.717587\n",
            "0.045076335901844344\n",
            "[244/1000] Train Acc: 0.694365 Loss: 1.011124 | Val Acc: 0.763932 loss: 0.715285\n",
            "0.04864630753148236\n",
            "[245/1000] Train Acc: 0.693855 Loss: 1.013019 | Val Acc: 0.762736 loss: 0.719767\n",
            "0.04296894628408654\n",
            "[246/1000] Train Acc: 0.694795 Loss: 1.009717 | Val Acc: 0.763688 loss: 0.717615\n",
            "0.046072369029330984\n",
            "[247/1000] Train Acc: 0.694056 Loss: 1.014108 | Val Acc: 0.763070 loss: 0.716855\n",
            "0.04621508080951198\n",
            "[248/1000] Train Acc: 0.694170 Loss: 1.012612 | Val Acc: 0.763574 loss: 0.715850\n",
            "0.04772421998646015\n",
            "[249/1000] Train Acc: 0.694285 Loss: 1.012159 | Val Acc: 0.763379 loss: 0.715378\n",
            "0.04800085719628988\n",
            "[250/1000] Train Acc: 0.693771 Loss: 1.011789 | Val Acc: 0.762582 loss: 0.717265\n",
            "0.04531714116508889\n",
            "[251/1000] Train Acc: 0.694306 Loss: 1.011708 | Val Acc: 0.763558 loss: 0.715956\n",
            "0.04760120764489806\n",
            "[252/1000] Train Acc: 0.694493 Loss: 1.011080 | Val Acc: 0.763501 loss: 0.715423\n",
            "0.04807803436449365\n",
            "[253/1000] Train Acc: 0.694554 Loss: 1.010660 | Val Acc: 0.762915 loss: 0.715683\n",
            "0.04723222537208327\n",
            "[254/1000] Train Acc: 0.694439 Loss: 1.010867 | Val Acc: 0.762330 loss: 0.717510\n",
            "0.0448201797014951\n",
            "[255/1000] Train Acc: 0.694502 Loss: 1.011937 | Val Acc: 0.763403 loss: 0.716101\n",
            "0.047301653863696225\n",
            "[256/1000] Train Acc: 0.694484 Loss: 1.010636 | Val Acc: 0.763769 loss: 0.714778\n",
            "0.048991215871278304\n",
            "[257/1000] Train Acc: 0.694577 Loss: 1.010508 | Val Acc: 0.763988 loss: 0.716074\n",
            "0.04791462002499902\n",
            "[258/1000] Train Acc: 0.694731 Loss: 1.011157 | Val Acc: 0.763330 loss: 0.716496\n",
            "0.046833474057251356\n",
            "[259/1000] Train Acc: 0.694078 Loss: 1.010283 | Val Acc: 0.763232 loss: 0.714957\n",
            "0.04827545336215788\n",
            "[260/1000] Train Acc: 0.694660 Loss: 1.010894 | Val Acc: 0.764249 loss: 0.714188\n",
            "0.05006063893429369\n",
            "[261/1000] Train Acc: 0.695113 Loss: 1.010619 | Val Acc: 0.764054 loss: 0.716239\n",
            "0.04781441113365259\n",
            "[262/1000] Train Acc: 0.694558 Loss: 1.011730 | Val Acc: 0.763777 loss: 0.714893\n",
            "0.04888435968527638\n",
            "[263/1000] Train Acc: 0.694338 Loss: 1.011180 | Val Acc: 0.764436 loss: 0.715100\n",
            "0.04933589355222123\n",
            "[264/1000] Train Acc: 0.694511 Loss: 1.010692 | Val Acc: 0.764249 loss: 0.712429\n",
            "0.05181921146620316\n",
            "[265/1000] Train Acc: 0.694096 Loss: 1.010849 | Val Acc: 0.763330 loss: 0.715279\n",
            "0.04805049191913702\n",
            "[266/1000] Train Acc: 0.694704 Loss: 1.010493 | Val Acc: 0.764566 loss: 0.714880\n",
            "0.049685882650023494\n",
            "[267/1000] Train Acc: 0.695325 Loss: 1.008653 | Val Acc: 0.764135 loss: 0.715072\n",
            "0.049062360096348345\n",
            "[268/1000] Train Acc: 0.695005 Loss: 1.009808 | Val Acc: 0.764289 loss: 0.714561\n",
            "0.049728589682820346\n",
            "[269/1000] Train Acc: 0.694685 Loss: 1.010033 | Val Acc: 0.763427 loss: 0.715825\n",
            "0.04760200641931722\n",
            "[270/1000] Train Acc: 0.694309 Loss: 1.012300 | Val Acc: 0.763972 loss: 0.716066\n",
            "0.047906306500527185\n",
            "[271/1000] Train Acc: 0.694538 Loss: 1.010406 | Val Acc: 0.764777 loss: 0.712314\n",
            "0.05246329951866868\n",
            "saving drive done\n",
            "saving model with acc 0.765\n",
            "[272/1000] Train Acc: 0.694536 Loss: 1.010059 | Val Acc: 0.765574 loss: 0.711932\n",
            "0.05364182347745883\n",
            "saving drive done\n",
            "saving model with acc 0.766\n",
            "[273/1000] Train Acc: 0.695047 Loss: 1.009112 | Val Acc: 0.763525 loss: 0.713602\n",
            "0.04992293564871653\n",
            "[274/1000] Train Acc: 0.694732 Loss: 1.010662 | Val Acc: 0.763972 loss: 0.714680\n",
            "0.04929215873467763\n",
            "[275/1000] Train Acc: 0.694779 Loss: 1.010235 | Val Acc: 0.763216 loss: 0.715493\n",
            "0.04772281704073267\n",
            "[276/1000] Train Acc: 0.695333 Loss: 1.010491 | Val Acc: 0.763769 loss: 0.715378\n",
            "0.04839077593123664\n",
            "[277/1000] Train Acc: 0.694770 Loss: 1.010513 | Val Acc: 0.763801 loss: 0.715224\n",
            "0.04857751361872886\n",
            "[278/1000] Train Acc: 0.695247 Loss: 1.008422 | Val Acc: 0.764558 loss: 0.715054\n",
            "0.049503169343762865\n",
            "[279/1000] Train Acc: 0.693821 Loss: 1.009547 | Val Acc: 0.764127 loss: 0.716323\n",
            "0.04780371501228864\n",
            "[280/1000] Train Acc: 0.694466 Loss: 1.009945 | Val Acc: 0.763314 loss: 0.715039\n",
            "0.048274523405841485\n",
            "[281/1000] Train Acc: 0.694685 Loss: 1.009118 | Val Acc: 0.764322 loss: 0.714248\n",
            "0.050073351446836334\n",
            "[282/1000] Train Acc: 0.694150 Loss: 1.009898 | Val Acc: 0.763940 loss: 0.715813\n",
            "0.04812654806762584\n",
            "[283/1000] Train Acc: 0.695551 Loss: 1.008952 | Val Acc: 0.763289 loss: 0.713655\n",
            "0.04963394873187377\n",
            "[284/1000] Train Acc: 0.694876 Loss: 1.008440 | Val Acc: 0.763045 loss: 0.714117\n",
            "0.04892805313681692\n",
            "[285/1000] Train Acc: 0.695419 Loss: 1.006689 | Val Acc: 0.764167 loss: 0.712261\n",
            "0.05190642593010042\n",
            "[286/1000] Train Acc: 0.695008 Loss: 1.009949 | Val Acc: 0.764956 loss: 0.713896\n",
            "0.05105987222876773\n",
            "[287/1000] Train Acc: 0.695398 Loss: 1.006372 | Val Acc: 0.764346 loss: 0.713532\n",
            "0.05081425312603538\n",
            "[288/1000] Train Acc: 0.694900 Loss: 1.008776 | Val Acc: 0.765167 loss: 0.711480\n",
            "0.05368758190411582\n",
            "[289/1000] Train Acc: 0.694910 Loss: 1.009204 | Val Acc: 0.764956 loss: 0.712368\n",
            "0.052587535785308614\n",
            "[290/1000] Train Acc: 0.694818 Loss: 1.009092 | Val Acc: 0.764078 loss: 0.712244\n",
            "0.051833557566045685\n",
            "[291/1000] Train Acc: 0.694802 Loss: 1.008477 | Val Acc: 0.763736 loss: 0.713178\n",
            "0.05055858027041937\n",
            "[292/1000] Train Acc: 0.695377 Loss: 1.007061 | Val Acc: 0.764167 loss: 0.713602\n",
            "0.050565369978633035\n",
            "[293/1000] Train Acc: 0.694759 Loss: 1.008510 | Val Acc: 0.764663 loss: 0.711052\n",
            "0.05361115516385917\n",
            "[294/1000] Train Acc: 0.695590 Loss: 1.007081 | Val Acc: 0.765070 loss: 0.709679\n",
            "0.05539108603749121\n",
            "[295/1000] Train Acc: 0.694991 Loss: 1.008676 | Val Acc: 0.764997 loss: 0.709774\n",
            "0.05522227409694214\n",
            "[296/1000] Train Acc: 0.694930 Loss: 1.008527 | Val Acc: 0.764452 loss: 0.712871\n",
            "0.05158060203642967\n",
            "[297/1000] Train Acc: 0.695554 Loss: 1.007794 | Val Acc: 0.765338 loss: 0.711475\n",
            "0.05386350885270519\n",
            "[298/1000] Train Acc: 0.695085 Loss: 1.009543 | Val Acc: 0.764265 loss: 0.713119\n",
            "0.05114614344525914\n",
            "[299/1000] Train Acc: 0.694813 Loss: 1.007956 | Val Acc: 0.763704 loss: 0.713043\n",
            "0.0506605350146484\n",
            "[300/1000] Train Acc: 0.695000 Loss: 1.008760 | Val Acc: 0.765159 loss: 0.711322\n",
            "0.053837556865493186\n",
            "[301/1000] Train Acc: 0.695688 Loss: 1.007331 | Val Acc: 0.764208 loss: 0.713428\n",
            "0.0507803237463067\n",
            "[302/1000] Train Acc: 0.695133 Loss: 1.007597 | Val Acc: 0.765354 loss: 0.712675\n",
            "0.0526792460540787\n",
            "[303/1000] Train Acc: 0.695508 Loss: 1.006367 | Val Acc: 0.764314 loss: 0.712307\n",
            "0.052006406867823984\n",
            "[304/1000] Train Acc: 0.695689 Loss: 1.007659 | Val Acc: 0.764753 loss: 0.712136\n",
            "0.05261697133995569\n",
            "[305/1000] Train Acc: 0.695333 Loss: 1.007155 | Val Acc: 0.763590 loss: 0.712124\n",
            "0.05146599536389718\n",
            "[306/1000] Train Acc: 0.695526 Loss: 1.007910 | Val Acc: 0.765062 loss: 0.713357\n",
            "0.0517043863861566\n",
            "[307/1000] Train Acc: 0.695642 Loss: 1.007436 | Val Acc: 0.764216 loss: 0.711874\n",
            "0.05234211369237851\n",
            "[308/1000] Train Acc: 0.695352 Loss: 1.006541 | Val Acc: 0.764647 loss: 0.712872\n",
            "0.05177552324239276\n",
            "[309/1000] Train Acc: 0.695750 Loss: 1.006311 | Val Acc: 0.763858 loss: 0.711590\n",
            "0.05226867107074473\n",
            "[310/1000] Train Acc: 0.694879 Loss: 1.008671 | Val Acc: 0.763216 loss: 0.712749\n",
            "0.05046675708398829\n",
            "[311/1000] Train Acc: 0.695317 Loss: 1.007113 | Val Acc: 0.764875 loss: 0.711337\n",
            "0.05353812057277474\n",
            "[312/1000] Train Acc: 0.695285 Loss: 1.007639 | Val Acc: 0.765135 loss: 0.709497\n",
            "0.055638192296692646\n",
            "[313/1000] Train Acc: 0.695138 Loss: 1.008251 | Val Acc: 0.765484 loss: 0.710112\n",
            "0.05537227382132759\n",
            "[314/1000] Train Acc: 0.695887 Loss: 1.006539 | Val Acc: 0.765200 loss: 0.708213\n",
            "0.056986759439181967\n",
            "[315/1000] Train Acc: 0.695198 Loss: 1.007458 | Val Acc: 0.764883 loss: 0.711227\n",
            "0.053655626446110216\n",
            "[316/1000] Train Acc: 0.695702 Loss: 1.006001 | Val Acc: 0.764671 loss: 0.710332\n",
            "0.05433973909793399\n",
            "[317/1000] Train Acc: 0.695240 Loss: 1.007712 | Val Acc: 0.765476 loss: 0.710363\n",
            "0.05511302693969877\n",
            "[318/1000] Train Acc: 0.695966 Loss: 1.006187 | Val Acc: 0.764558 loss: 0.710249\n",
            "0.05430904339294185\n",
            "[319/1000] Train Acc: 0.695363 Loss: 1.007862 | Val Acc: 0.765232 loss: 0.710593\n",
            "0.054639340961202265\n",
            "[320/1000] Train Acc: 0.695670 Loss: 1.006776 | Val Acc: 0.764704 loss: 0.713058\n",
            "0.05164639401533444\n",
            "[321/1000] Train Acc: 0.696000 Loss: 1.004651 | Val Acc: 0.764818 loss: 0.710896\n",
            "0.05392176434673124\n",
            "[322/1000] Train Acc: 0.696342 Loss: 1.004767 | Val Acc: 0.763875 loss: 0.713629\n",
            "0.05024606123836162\n",
            "[323/1000] Train Acc: 0.695171 Loss: 1.007526 | Val Acc: 0.764102 loss: 0.712601\n",
            "0.051501242483244614\n",
            "[324/1000] Train Acc: 0.696202 Loss: 1.004704 | Val Acc: 0.765297 loss: 0.708784\n",
            "0.05651301533235065\n",
            "[325/1000] Train Acc: 0.695849 Loss: 1.006487 | Val Acc: 0.765249 loss: 0.710843\n",
            "0.054405651583681824\n",
            "[326/1000] Train Acc: 0.696200 Loss: 1.006183 | Val Acc: 0.765078 loss: 0.710865\n",
            "0.05421332536203416\n",
            "[327/1000] Train Acc: 0.695757 Loss: 1.006575 | Val Acc: 0.765411 loss: 0.709731\n",
            "0.05568040681193276\n",
            "[328/1000] Train Acc: 0.695731 Loss: 1.006522 | Val Acc: 0.765501 loss: 0.711763\n",
            "0.05373818916092221\n",
            "[329/1000] Train Acc: 0.695533 Loss: 1.006491 | Val Acc: 0.764110 loss: 0.712331\n",
            "0.05177982462704789\n",
            "[330/1000] Train Acc: 0.696119 Loss: 1.005155 | Val Acc: 0.764525 loss: 0.711552\n",
            "0.052972708401795576\n",
            "[331/1000] Train Acc: 0.695576 Loss: 1.006494 | Val Acc: 0.764923 loss: 0.710108\n",
            "0.05481512905907482\n",
            "[332/1000] Train Acc: 0.696169 Loss: 1.006566 | Val Acc: 0.763972 loss: 0.712076\n",
            "0.05189578828111441\n",
            "[333/1000] Train Acc: 0.696231 Loss: 1.006427 | Val Acc: 0.765647 loss: 0.708592\n",
            "0.057055315390416084\n",
            "saving drive done\n",
            "saving model with acc 0.766\n",
            "[334/1000] Train Acc: 0.695464 Loss: 1.005671 | Val Acc: 0.764484 loss: 0.709667\n",
            "0.05481718592339169\n",
            "[335/1000] Train Acc: 0.696052 Loss: 1.006504 | Val Acc: 0.764387 loss: 0.710065\n",
            "0.054321425980100035\n",
            "[336/1000] Train Acc: 0.695283 Loss: 1.005688 | Val Acc: 0.765127 loss: 0.710027\n",
            "0.05509985698768305\n",
            "[337/1000] Train Acc: 0.696016 Loss: 1.005099 | Val Acc: 0.764379 loss: 0.712367\n",
            "0.052011368288444215\n",
            "[338/1000] Train Acc: 0.696143 Loss: 1.007267 | Val Acc: 0.765241 loss: 0.708902\n",
            "0.056339032261885524\n",
            "[339/1000] Train Acc: 0.696052 Loss: 1.006159 | Val Acc: 0.766045 loss: 0.707819\n",
            "0.058226950948185086\n",
            "saving drive done\n",
            "saving model with acc 0.766\n",
            "[340/1000] Train Acc: 0.695679 Loss: 1.005896 | Val Acc: 0.764883 loss: 0.709940\n",
            "0.05494317933006476\n",
            "[341/1000] Train Acc: 0.695494 Loss: 1.004264 | Val Acc: 0.764013 loss: 0.712640\n",
            "0.051372841198538355\n",
            "[342/1000] Train Acc: 0.695231 Loss: 1.007321 | Val Acc: 0.763907 loss: 0.711711\n",
            "0.052195829109847436\n",
            "[343/1000] Train Acc: 0.696551 Loss: 1.003400 | Val Acc: 0.764558 loss: 0.710093\n",
            "0.05446445644681108\n",
            "[344/1000] Train Acc: 0.696135 Loss: 1.004650 | Val Acc: 0.764102 loss: 0.710898\n",
            "0.05320423513767292\n",
            "[345/1000] Train Acc: 0.695921 Loss: 1.006301 | Val Acc: 0.765281 loss: 0.710104\n",
            "0.05517689994258801\n",
            "[346/1000] Train Acc: 0.696870 Loss: 1.004693 | Val Acc: 0.765192 loss: 0.709354\n",
            "0.055838198415853246\n",
            "[347/1000] Train Acc: 0.696347 Loss: 1.005091 | Val Acc: 0.765688 loss: 0.708564\n",
            "0.05712382122430326\n",
            "[348/1000] Train Acc: 0.696339 Loss: 1.005544 | Val Acc: 0.766265 loss: 0.707837\n",
            "0.058427889559632074\n",
            "saving drive done\n",
            "saving model with acc 0.766\n",
            "[349/1000] Train Acc: 0.696011 Loss: 1.005684 | Val Acc: 0.765663 loss: 0.708466\n",
            "0.05719745147035227\n",
            "[350/1000] Train Acc: 0.696020 Loss: 1.006603 | Val Acc: 0.766021 loss: 0.708485\n",
            "0.057536177259832955\n",
            "[351/1000] Train Acc: 0.696152 Loss: 1.005573 | Val Acc: 0.766574 loss: 0.707921\n",
            "0.05865291449470056\n",
            "saving drive done\n",
            "saving model with acc 0.767\n",
            "[352/1000] Train Acc: 0.696323 Loss: 1.004342 | Val Acc: 0.765232 loss: 0.709302\n",
            "0.05593018780135517\n",
            "[353/1000] Train Acc: 0.695376 Loss: 1.006413 | Val Acc: 0.765517 loss: 0.709520\n",
            "0.05599711829573373\n",
            "[354/1000] Train Acc: 0.695527 Loss: 1.005049 | Val Acc: 0.765924 loss: 0.708064\n",
            "0.05785914390655045\n",
            "[355/1000] Train Acc: 0.695501 Loss: 1.005447 | Val Acc: 0.765737 loss: 0.709002\n",
            "0.05673492233926858\n",
            "[356/1000] Train Acc: 0.695748 Loss: 1.005910 | Val Acc: 0.765989 loss: 0.707988\n",
            "0.0580008901365624\n",
            "[357/1000] Train Acc: 0.696304 Loss: 1.004306 | Val Acc: 0.765574 loss: 0.708387\n",
            "0.057186595245672156\n",
            "[358/1000] Train Acc: 0.695601 Loss: 1.006131 | Val Acc: 0.766224 loss: 0.709295\n",
            "0.05692920157891246\n",
            "[359/1000] Train Acc: 0.696502 Loss: 1.003828 | Val Acc: 0.765655 loss: 0.708505\n",
            "0.05715044732771091\n",
            "[360/1000] Train Acc: 0.696451 Loss: 1.004627 | Val Acc: 0.765940 loss: 0.709711\n",
            "0.056228337695444\n",
            "[361/1000] Train Acc: 0.696237 Loss: 1.003831 | Val Acc: 0.765509 loss: 0.709257\n",
            "0.056251775537876414\n",
            "[362/1000] Train Acc: 0.696181 Loss: 1.004980 | Val Acc: 0.765493 loss: 0.710297\n",
            "0.05519523461987441\n",
            "[363/1000] Train Acc: 0.695873 Loss: 1.005335 | Val Acc: 0.765948 loss: 0.707129\n",
            "0.05881858708191767\n",
            "[364/1000] Train Acc: 0.695558 Loss: 1.005422 | Val Acc: 0.766281 loss: 0.708756\n",
            "0.05752566896197786\n",
            "[365/1000] Train Acc: 0.696564 Loss: 1.004347 | Val Acc: 0.766330 loss: 0.708256\n",
            "0.05807375741884713\n",
            "[366/1000] Train Acc: 0.696472 Loss: 1.004052 | Val Acc: 0.766346 loss: 0.707830\n",
            "0.05851666449678439\n",
            "[367/1000] Train Acc: 0.696264 Loss: 1.002464 | Val Acc: 0.765314 loss: 0.709694\n",
            "0.05561935216870095\n",
            "[368/1000] Train Acc: 0.696155 Loss: 1.004139 | Val Acc: 0.766777 loss: 0.707397\n",
            "0.05938002611001025\n",
            "saving drive done\n",
            "saving model with acc 0.767\n",
            "[369/1000] Train Acc: 0.696341 Loss: 1.004324 | Val Acc: 0.766111 loss: 0.708432\n",
            "0.05767856029197249\n",
            "[370/1000] Train Acc: 0.696676 Loss: 1.004691 | Val Acc: 0.766420 loss: 0.708195\n",
            "0.058224321600384155\n",
            "[371/1000] Train Acc: 0.696169 Loss: 1.003963 | Val Acc: 0.767485 loss: 0.707184\n",
            "0.06030086107599775\n",
            "saving drive done\n",
            "saving model with acc 0.767\n",
            "[372/1000] Train Acc: 0.696314 Loss: 1.004945 | Val Acc: 0.766159 loss: 0.708638\n",
            "0.05752150375227616\n",
            "[373/1000] Train Acc: 0.695683 Loss: 1.004414 | Val Acc: 0.766696 loss: 0.707726\n",
            "0.058970117822888635\n",
            "[374/1000] Train Acc: 0.696651 Loss: 1.003376 | Val Acc: 0.764923 loss: 0.712649\n",
            "0.05227399309278169\n",
            "[375/1000] Train Acc: 0.696693 Loss: 1.003573 | Val Acc: 0.765858 loss: 0.709764\n",
            "0.05609471573897207\n",
            "[376/1000] Train Acc: 0.696352 Loss: 1.005238 | Val Acc: 0.766428 loss: 0.708871\n",
            "0.05755711463769442\n",
            "[377/1000] Train Acc: 0.696345 Loss: 1.003657 | Val Acc: 0.766842 loss: 0.708690\n",
            "0.05815221654880298\n",
            "[378/1000] Train Acc: 0.696225 Loss: 1.005068 | Val Acc: 0.765948 loss: 0.708829\n",
            "0.05711881084919057\n",
            "[379/1000] Train Acc: 0.696677 Loss: 1.003229 | Val Acc: 0.766639 loss: 0.706554\n",
            "0.060084683033945985\n",
            "[380/1000] Train Acc: 0.697175 Loss: 1.002568 | Val Acc: 0.766615 loss: 0.707070\n",
            "0.05954489808721242\n",
            "[381/1000] Train Acc: 0.696133 Loss: 1.003816 | Val Acc: 0.765907 loss: 0.707915\n",
            "0.057992660312748634\n",
            "[382/1000] Train Acc: 0.696134 Loss: 1.004354 | Val Acc: 0.765119 loss: 0.709905\n",
            "0.055213308597236055\n",
            "[383/1000] Train Acc: 0.696698 Loss: 1.003300 | Val Acc: 0.766387 loss: 0.707396\n",
            "0.058991290018442166\n",
            "[384/1000] Train Acc: 0.696625 Loss: 1.002609 | Val Acc: 0.766322 loss: 0.708079\n",
            "0.05824336707093569\n",
            "[385/1000] Train Acc: 0.696363 Loss: 1.004393 | Val Acc: 0.765566 loss: 0.709239\n",
            "0.05632646957874721\n",
            "[386/1000] Train Acc: 0.695508 Loss: 1.005513 | Val Acc: 0.765850 loss: 0.708404\n",
            "0.0574463263964039\n",
            "[387/1000] Train Acc: 0.696315 Loss: 1.004123 | Val Acc: 0.763988 loss: 0.712191\n",
            "0.05179739146466755\n",
            "[388/1000] Train Acc: 0.696219 Loss: 1.003514 | Val Acc: 0.766216 loss: 0.707173\n",
            "0.05904340956850018\n",
            "[389/1000] Train Acc: 0.695867 Loss: 1.005225 | Val Acc: 0.765867 loss: 0.707157\n",
            "0.05870990104357143\n",
            "[390/1000] Train Acc: 0.696221 Loss: 1.004591 | Val Acc: 0.765452 loss: 0.708775\n",
            "0.05667690458072827\n",
            "[391/1000] Train Acc: 0.696600 Loss: 1.002899 | Val Acc: 0.765989 loss: 0.708308\n",
            "0.057681017352141706\n",
            "[392/1000] Train Acc: 0.696775 Loss: 1.002713 | Val Acc: 0.764923 loss: 0.709739\n",
            "0.055184677614386946\n",
            "[393/1000] Train Acc: 0.697311 Loss: 1.001941 | Val Acc: 0.766200 loss: 0.707392\n",
            "0.058807847956866555\n",
            "[394/1000] Train Acc: 0.696073 Loss: 1.002993 | Val Acc: 0.766338 loss: 0.707396\n",
            "0.05894185973793287\n",
            "[395/1000] Train Acc: 0.696698 Loss: 1.002762 | Val Acc: 0.766981 loss: 0.705809\n",
            "0.06117122072970538\n",
            "[396/1000] Train Acc: 0.696081 Loss: 1.004725 | Val Acc: 0.765216 loss: 0.709081\n",
            "0.05613537418928494\n",
            "[397/1000] Train Acc: 0.696997 Loss: 1.003379 | Val Acc: 0.765330 loss: 0.709927\n",
            "0.055402543844221164\n",
            "[398/1000] Train Acc: 0.696557 Loss: 1.003271 | Val Acc: 0.766273 loss: 0.708164\n",
            "0.058109073684016854\n",
            "[399/1000] Train Acc: 0.696535 Loss: 1.001859 | Val Acc: 0.765793 loss: 0.706250\n",
            "0.05954384406459445\n",
            "[400/1000] Train Acc: 0.696399 Loss: 1.002381 | Val Acc: 0.766045 loss: 0.706678\n",
            "0.05936782823768583\n",
            "[401/1000] Train Acc: 0.696212 Loss: 1.004275 | Val Acc: 0.765119 loss: 0.707394\n",
            "0.05772448663909735\n",
            "[402/1000] Train Acc: 0.696542 Loss: 1.002134 | Val Acc: 0.765964 loss: 0.708328\n",
            "0.057636504165682\n",
            "[403/1000] Train Acc: 0.697117 Loss: 1.002153 | Val Acc: 0.765802 loss: 0.706484\n",
            "0.059317710116388866\n",
            "[404/1000] Train Acc: 0.696330 Loss: 1.002850 | Val Acc: 0.766997 loss: 0.707281\n",
            "0.05971601309732333\n",
            "[405/1000] Train Acc: 0.696539 Loss: 1.003083 | Val Acc: 0.766232 loss: 0.706663\n",
            "0.05956967863652107\n",
            "[406/1000] Train Acc: 0.696773 Loss: 1.002205 | Val Acc: 0.766184 loss: 0.710647\n",
            "0.05553652588634095\n",
            "[407/1000] Train Acc: 0.696774 Loss: 1.002346 | Val Acc: 0.765940 loss: 0.707312\n",
            "0.058628098761648206\n",
            "[408/1000] Train Acc: 0.696429 Loss: 1.002847 | Val Acc: 0.766428 loss: 0.706220\n",
            "0.06020768206654681\n",
            "[409/1000] Train Acc: 0.697097 Loss: 1.002304 | Val Acc: 0.765151 loss: 0.707541\n",
            "0.05760991267084725\n",
            "[410/1000] Train Acc: 0.696482 Loss: 1.003458 | Val Acc: 0.764371 loss: 0.710284\n",
            "0.054086323033476824\n",
            "[411/1000] Train Acc: 0.696689 Loss: 1.003352 | Val Acc: 0.765387 loss: 0.708081\n",
            "0.05730596057720938\n",
            "[412/1000] Train Acc: 0.696747 Loss: 1.002215 | Val Acc: 0.765704 loss: 0.707284\n",
            "0.058420082234861725\n",
            "[413/1000] Train Acc: 0.696910 Loss: 1.002396 | Val Acc: 0.765517 loss: 0.707798\n",
            "0.0577186913170874\n",
            "[414/1000] Train Acc: 0.696801 Loss: 1.002673 | Val Acc: 0.765476 loss: 0.710559\n",
            "0.054916912539160756\n",
            "[415/1000] Train Acc: 0.696845 Loss: 1.002845 | Val Acc: 0.766135 loss: 0.708123\n",
            "0.05801221643404164\n",
            "[416/1000] Train Acc: 0.697157 Loss: 1.002585 | Val Acc: 0.766045 loss: 0.706561\n",
            "0.05948442916983032\n",
            "[417/1000] Train Acc: 0.696821 Loss: 1.002272 | Val Acc: 0.764509 loss: 0.709941\n",
            "0.05456757160678971\n",
            "[418/1000] Train Acc: 0.696590 Loss: 1.002354 | Val Acc: 0.764696 loss: 0.709862\n",
            "0.05483340739795506\n",
            "[419/1000] Train Acc: 0.696103 Loss: 1.003062 | Val Acc: 0.766672 loss: 0.707049\n",
            "0.059622448547421714\n",
            "[420/1000] Train Acc: 0.696821 Loss: 1.003557 | Val Acc: 0.766208 loss: 0.708768\n",
            "0.057439667547400486\n",
            "[421/1000] Train Acc: 0.696918 Loss: 1.001490 | Val Acc: 0.766192 loss: 0.706127\n",
            "0.060064977014289034\n",
            "[422/1000] Train Acc: 0.696644 Loss: 1.002206 | Val Acc: 0.765712 loss: 0.708205\n",
            "0.05750695949485696\n",
            "[423/1000] Train Acc: 0.696635 Loss: 1.002083 | Val Acc: 0.765712 loss: 0.707346\n",
            "0.058365962057899345\n",
            "[424/1000] Train Acc: 0.696591 Loss: 1.001982 | Val Acc: 0.765777 loss: 0.707935\n",
            "0.057842162630512894\n",
            "[425/1000] Train Acc: 0.696823 Loss: 1.003018 | Val Acc: 0.766420 loss: 0.705321\n",
            "0.061098061273254345\n",
            "[426/1000] Train Acc: 0.697174 Loss: 1.001226 | Val Acc: 0.765533 loss: 0.708647\n",
            "0.056886316702116635\n",
            "[427/1000] Train Acc: 0.697274 Loss: 1.000335 | Val Acc: 0.767021 loss: 0.704453\n",
            "0.06256776297073763\n",
            "[428/1000] Train Acc: 0.696268 Loss: 1.001884 | Val Acc: 0.766078 loss: 0.705043\n",
            "0.06103483114130759\n",
            "[429/1000] Train Acc: 0.697195 Loss: 1.001961 | Val Acc: 0.766436 loss: 0.705274\n",
            "0.061161392113970536\n",
            "[430/1000] Train Acc: 0.696880 Loss: 1.001405 | Val Acc: 0.767054 loss: 0.705384\n",
            "0.06166987430728432\n",
            "[431/1000] Train Acc: 0.696442 Loss: 1.003236 | Val Acc: 0.766387 loss: 0.706449\n",
            "0.05993751414192394\n",
            "[432/1000] Train Acc: 0.696395 Loss: 1.002869 | Val Acc: 0.767119 loss: 0.705404\n",
            "0.06171446666237934\n",
            "[433/1000] Train Acc: 0.697080 Loss: 1.002087 | Val Acc: 0.765875 loss: 0.707828\n",
            "0.058046280002921335\n",
            "[434/1000] Train Acc: 0.696509 Loss: 1.002980 | Val Acc: 0.767891 loss: 0.702645\n",
            "0.06524630619586491\n",
            "saving drive done\n",
            "saving model with acc 0.768\n",
            "[435/1000] Train Acc: 0.696692 Loss: 1.001632 | Val Acc: 0.765785 loss: 0.705709\n",
            "0.06007611585178396\n",
            "[436/1000] Train Acc: 0.697387 Loss: 1.000396 | Val Acc: 0.765948 loss: 0.706810\n",
            "0.05913808338789517\n",
            "[437/1000] Train Acc: 0.696489 Loss: 1.003850 | Val Acc: 0.767265 loss: 0.705397\n",
            "0.06186846215300246\n",
            "[438/1000] Train Acc: 0.696919 Loss: 1.002360 | Val Acc: 0.765777 loss: 0.707034\n",
            "0.05874289382385378\n",
            "[439/1000] Train Acc: 0.696743 Loss: 1.001770 | Val Acc: 0.767102 loss: 0.705476\n",
            "0.06162622868821954\n",
            "[440/1000] Train Acc: 0.696572 Loss: 1.003498 | Val Acc: 0.766964 loss: 0.707629\n",
            "0.059335636782709034\n",
            "[441/1000] Train Acc: 0.697013 Loss: 1.001344 | Val Acc: 0.765306 loss: 0.707638\n",
            "0.057667590464337115\n",
            "[442/1000] Train Acc: 0.697148 Loss: 1.002676 | Val Acc: 0.765899 loss: 0.706516\n",
            "0.05938277683064097\n",
            "[443/1000] Train Acc: 0.697192 Loss: 1.001384 | Val Acc: 0.766875 loss: 0.705405\n",
            "0.0614697425741888\n",
            "[444/1000] Train Acc: 0.696995 Loss: 1.003321 | Val Acc: 0.766663 loss: 0.705878\n",
            "0.06078493313393152\n",
            "[445/1000] Train Acc: 0.696701 Loss: 1.001981 | Val Acc: 0.767932 loss: 0.704913\n",
            "0.06301907294115094\n",
            "saving drive done\n",
            "saving model with acc 0.768\n",
            "[446/1000] Train Acc: 0.696770 Loss: 1.001315 | Val Acc: 0.766647 loss: 0.707067\n",
            "0.05958035506724457\n",
            "[447/1000] Train Acc: 0.696829 Loss: 1.000563 | Val Acc: 0.766403 loss: 0.705123\n",
            "0.061280344697576816\n",
            "[448/1000] Train Acc: 0.696062 Loss: 1.002115 | Val Acc: 0.766623 loss: 0.704528\n",
            "0.06209461253543214\n",
            "[449/1000] Train Acc: 0.697566 Loss: 1.000275 | Val Acc: 0.766037 loss: 0.706244\n",
            "0.059793050082858734\n",
            "[450/1000] Train Acc: 0.697076 Loss: 0.999986 | Val Acc: 0.766672 loss: 0.702880\n",
            "0.06379177900866007\n",
            "[451/1000] Train Acc: 0.697453 Loss: 1.001885 | Val Acc: 0.765639 loss: 0.706568\n",
            "0.0590709423372876\n",
            "[452/1000] Train Acc: 0.697045 Loss: 1.001242 | Val Acc: 0.765655 loss: 0.705623\n",
            "0.06003187488519868\n",
            "[453/1000] Train Acc: 0.696920 Loss: 1.001537 | Val Acc: 0.767102 loss: 0.702822\n",
            "0.06428078386164382\n",
            "[454/1000] Train Acc: 0.696560 Loss: 1.001131 | Val Acc: 0.766379 loss: 0.707445\n",
            "0.05893346239919539\n",
            "[455/1000] Train Acc: 0.696680 Loss: 1.002174 | Val Acc: 0.766330 loss: 0.703836\n",
            "0.06249356932473127\n",
            "[456/1000] Train Acc: 0.696954 Loss: 1.001577 | Val Acc: 0.766525 loss: 0.705519\n",
            "0.06100580091434371\n",
            "[457/1000] Train Acc: 0.697518 Loss: 1.000279 | Val Acc: 0.766379 loss: 0.704845\n",
            "0.06153383539982882\n",
            "[458/1000] Train Acc: 0.697181 Loss: 1.000836 | Val Acc: 0.766468 loss: 0.706231\n",
            "0.06023756045619\n",
            "[459/1000] Train Acc: 0.696872 Loss: 1.002085 | Val Acc: 0.766037 loss: 0.705825\n",
            "0.06021220942546168\n",
            "[460/1000] Train Acc: 0.697084 Loss: 1.001686 | Val Acc: 0.767054 loss: 0.704243\n",
            "0.06281078081759861\n",
            "[461/1000] Train Acc: 0.697395 Loss: 1.001191 | Val Acc: 0.765924 loss: 0.705865\n",
            "0.06005833069101563\n",
            "[462/1000] Train Acc: 0.696696 Loss: 1.002197 | Val Acc: 0.766704 loss: 0.705574\n",
            "0.06113005457778642\n",
            "[463/1000] Train Acc: 0.696571 Loss: 1.002806 | Val Acc: 0.766728 loss: 0.706421\n",
            "0.06030720824233371\n",
            "[464/1000] Train Acc: 0.697393 Loss: 1.000658 | Val Acc: 0.766566 loss: 0.705153\n",
            "0.061412615443116936\n",
            "[465/1000] Train Acc: 0.697338 Loss: 1.001311 | Val Acc: 0.765818 loss: 0.705766\n",
            "0.06005187911928689\n",
            "[466/1000] Train Acc: 0.697419 Loss: 0.999454 | Val Acc: 0.767785 loss: 0.702690\n",
            "0.06509507387587743\n",
            "[467/1000] Train Acc: 0.697459 Loss: 1.000411 | Val Acc: 0.767761 loss: 0.704048\n",
            "0.06371278008586934\n",
            "[468/1000] Train Acc: 0.696948 Loss: 1.001457 | Val Acc: 0.766021 loss: 0.707651\n",
            "0.05837046337583596\n",
            "[469/1000] Train Acc: 0.696617 Loss: 1.001229 | Val Acc: 0.766192 loss: 0.703986\n",
            "0.06220549116709506\n",
            "[470/1000] Train Acc: 0.697341 Loss: 0.999957 | Val Acc: 0.766501 loss: 0.706229\n",
            "0.0602717840077478\n",
            "[471/1000] Train Acc: 0.696813 Loss: 1.000646 | Val Acc: 0.766184 loss: 0.705991\n",
            "0.060192896997164014\n",
            "[472/1000] Train Acc: 0.697181 Loss: 0.999361 | Val Acc: 0.766981 loss: 0.703818\n",
            "0.06316222578985475\n",
            "[473/1000] Train Acc: 0.696782 Loss: 1.000718 | Val Acc: 0.766314 loss: 0.705295\n",
            "0.06101905868560964\n",
            "[474/1000] Train Acc: 0.697397 Loss: 0.999900 | Val Acc: 0.767826 loss: 0.702740\n",
            "0.06508638665503819\n",
            "[475/1000] Train Acc: 0.696985 Loss: 1.000055 | Val Acc: 0.767054 loss: 0.704215\n",
            "0.06283909263619447\n",
            "[476/1000] Train Acc: 0.697284 Loss: 0.999784 | Val Acc: 0.765850 loss: 0.706414\n",
            "0.05943637545620195\n",
            "[477/1000] Train Acc: 0.697175 Loss: 0.999434 | Val Acc: 0.766940 loss: 0.702252\n",
            "0.06468773341625089\n",
            "[478/1000] Train Acc: 0.697360 Loss: 0.998896 | Val Acc: 0.767533 loss: 0.702442\n",
            "0.06509102731767669\n",
            "[479/1000] Train Acc: 0.697080 Loss: 0.999807 | Val Acc: 0.766956 loss: 0.701892\n",
            "0.06506417065427028\n",
            "[480/1000] Train Acc: 0.697181 Loss: 1.000237 | Val Acc: 0.768176 loss: 0.702359\n",
            "0.06581636952781811\n",
            "saving drive done\n",
            "saving model with acc 0.768\n",
            "[481/1000] Train Acc: 0.696878 Loss: 1.001609 | Val Acc: 0.766379 loss: 0.703897\n",
            "0.062481681302698266\n",
            "[482/1000] Train Acc: 0.697693 Loss: 0.999830 | Val Acc: 0.766550 loss: 0.704308\n",
            "0.06224183193263677\n",
            "[483/1000] Train Acc: 0.697289 Loss: 1.001616 | Val Acc: 0.767029 loss: 0.705153\n",
            "0.06187675378964941\n",
            "[484/1000] Train Acc: 0.697183 Loss: 1.001180 | Val Acc: 0.767037 loss: 0.702885\n",
            "0.0641524387425989\n",
            "[485/1000] Train Acc: 0.696949 Loss: 1.000091 | Val Acc: 0.766111 loss: 0.705036\n",
            "0.06107408081819177\n",
            "[486/1000] Train Acc: 0.696612 Loss: 1.001137 | Val Acc: 0.766558 loss: 0.704479\n",
            "0.062078778258423783\n",
            "[487/1000] Train Acc: 0.697162 Loss: 1.001043 | Val Acc: 0.766509 loss: 0.705483\n",
            "0.06102583962332453\n",
            "[488/1000] Train Acc: 0.697203 Loss: 1.001865 | Val Acc: 0.767143 loss: 0.703397\n",
            "0.06374561637311704\n",
            "[489/1000] Train Acc: 0.697560 Loss: 0.999591 | Val Acc: 0.767070 loss: 0.702242\n",
            "0.06482780411391675\n",
            "[490/1000] Train Acc: 0.697717 Loss: 0.998879 | Val Acc: 0.766159 loss: 0.704977\n",
            "0.061182136725071\n",
            "[491/1000] Train Acc: 0.697319 Loss: 1.001195 | Val Acc: 0.767826 loss: 0.702671\n",
            "0.06515499436334105\n",
            "[492/1000] Train Acc: 0.697361 Loss: 0.999096 | Val Acc: 0.766517 loss: 0.705019\n",
            "0.06149804658341751\n",
            "[493/1000] Train Acc: 0.697585 Loss: 0.999233 | Val Acc: 0.765972 loss: 0.704944\n",
            "0.061028414460102653\n",
            "[494/1000] Train Acc: 0.697644 Loss: 1.000246 | Val Acc: 0.767834 loss: 0.703195\n",
            "0.06463905051747232\n",
            "[495/1000] Train Acc: 0.697671 Loss: 0.999142 | Val Acc: 0.767745 loss: 0.704660\n",
            "0.06308452373929019\n",
            "[496/1000] Train Acc: 0.697277 Loss: 1.000940 | Val Acc: 0.766785 loss: 0.705688\n",
            "0.06109740293260235\n",
            "[497/1000] Train Acc: 0.697054 Loss: 1.000403 | Val Acc: 0.767785 loss: 0.703050\n",
            "0.06473545356448152\n",
            "[498/1000] Train Acc: 0.697972 Loss: 0.999563 | Val Acc: 0.765745 loss: 0.706579\n",
            "0.05916570410225652\n",
            "[499/1000] Train Acc: 0.697827 Loss: 0.999730 | Val Acc: 0.767680 loss: 0.702760\n",
            "0.06491953303722431\n",
            "[500/1000] Train Acc: 0.697927 Loss: 0.999828 | Val Acc: 0.765810 loss: 0.704299\n",
            "0.06151104194844137\n",
            "[501/1000] Train Acc: 0.697260 Loss: 1.000208 | Val Acc: 0.767346 loss: 0.703765\n",
            "0.06358142702523428\n",
            "[502/1000] Train Acc: 0.698337 Loss: 0.998206 | Val Acc: 0.767558 loss: 0.702431\n",
            "0.06512636594399257\n",
            "[503/1000] Train Acc: 0.697605 Loss: 0.999673 | Val Acc: 0.766485 loss: 0.705194\n",
            "0.06129047290509704\n",
            "[504/1000] Train Acc: 0.697896 Loss: 1.000858 | Val Acc: 0.766208 loss: 0.704735\n",
            "0.06147298394060918\n",
            "[505/1000] Train Acc: 0.697517 Loss: 0.999060 | Val Acc: 0.766029 loss: 0.705957\n",
            "0.06007232258952189\n",
            "[506/1000] Train Acc: 0.697720 Loss: 0.999410 | Val Acc: 0.767314 loss: 0.703906\n",
            "0.06340786952385102\n",
            "[507/1000] Train Acc: 0.697273 Loss: 1.000456 | Val Acc: 0.767013 loss: 0.703155\n",
            "0.06385791847723965\n",
            "[508/1000] Train Acc: 0.698240 Loss: 0.998758 | Val Acc: 0.765777 loss: 0.706694\n",
            "0.05908269757768336\n",
            "[509/1000] Train Acc: 0.697802 Loss: 1.000712 | Val Acc: 0.767387 loss: 0.705155\n",
            "0.062232437585159284\n",
            "[510/1000] Train Acc: 0.697544 Loss: 0.999701 | Val Acc: 0.766794 loss: 0.704035\n",
            "0.06275808304173924\n",
            "[511/1000] Train Acc: 0.697431 Loss: 0.998678 | Val Acc: 0.765834 loss: 0.704605\n",
            "0.06122931885199434\n",
            "[512/1000] Train Acc: 0.697689 Loss: 0.999793 | Val Acc: 0.767224 loss: 0.704672\n",
            "0.06255259492660559\n",
            "[513/1000] Train Acc: 0.697375 Loss: 1.000612 | Val Acc: 0.767875 loss: 0.703554\n",
            "0.0643204897971118\n",
            "[514/1000] Train Acc: 0.697623 Loss: 0.999711 | Val Acc: 0.767444 loss: 0.704216\n",
            "0.06322821877474283\n",
            "[515/1000] Train Acc: 0.697540 Loss: 0.997761 | Val Acc: 0.767403 loss: 0.702393\n",
            "0.06501069433336715\n",
            "[516/1000] Train Acc: 0.697677 Loss: 0.998819 | Val Acc: 0.766769 loss: 0.702793\n",
            "0.06397563501778303\n",
            "[517/1000] Train Acc: 0.697537 Loss: 0.999808 | Val Acc: 0.767607 loss: 0.702771\n",
            "0.06483525574757099\n",
            "[518/1000] Train Acc: 0.698029 Loss: 0.999507 | Val Acc: 0.766818 loss: 0.703833\n",
            "0.06298503901929253\n",
            "[519/1000] Train Acc: 0.697327 Loss: 0.999563 | Val Acc: 0.767249 loss: 0.702626\n",
            "0.06462321793449333\n",
            "[520/1000] Train Acc: 0.697465 Loss: 0.999369 | Val Acc: 0.766663 loss: 0.703158\n",
            "0.06350563322927105\n",
            "[521/1000] Train Acc: 0.697438 Loss: 1.000236 | Val Acc: 0.767753 loss: 0.701256\n",
            "0.06649722602371189\n",
            "[522/1000] Train Acc: 0.697519 Loss: 0.999002 | Val Acc: 0.766704 loss: 0.702974\n",
            "0.06373032314914384\n",
            "[523/1000] Train Acc: 0.697635 Loss: 0.998528 | Val Acc: 0.768436 loss: 0.701948\n",
            "0.06648833717480773\n",
            "saving drive done\n",
            "saving model with acc 0.768\n",
            "[524/1000] Train Acc: 0.697950 Loss: 0.998595 | Val Acc: 0.766745 loss: 0.704529\n",
            "0.062215908867862546\n",
            "[525/1000] Train Acc: 0.697893 Loss: 0.999796 | Val Acc: 0.768037 loss: 0.701574\n",
            "0.06646315639905953\n",
            "[526/1000] Train Acc: 0.697484 Loss: 0.999614 | Val Acc: 0.766346 loss: 0.707385\n",
            "0.058961640549402006\n",
            "[527/1000] Train Acc: 0.697702 Loss: 0.998094 | Val Acc: 0.767249 loss: 0.703530\n",
            "0.06371887610499183\n",
            "[528/1000] Train Acc: 0.697881 Loss: 0.999169 | Val Acc: 0.767322 loss: 0.702324\n",
            "0.06499800709976455\n",
            "[529/1000] Train Acc: 0.697783 Loss: 0.998779 | Val Acc: 0.766428 loss: 0.702172\n",
            "0.064255548535054\n",
            "[530/1000] Train Acc: 0.698204 Loss: 0.997947 | Val Acc: 0.766615 loss: 0.702963\n",
            "0.06365148109128771\n",
            "[531/1000] Train Acc: 0.697690 Loss: 0.999314 | Val Acc: 0.767070 loss: 0.702179\n",
            "0.06489099695830758\n",
            "[532/1000] Train Acc: 0.697340 Loss: 0.998692 | Val Acc: 0.765623 loss: 0.703142\n",
            "0.062480538006630115\n",
            "[533/1000] Train Acc: 0.697693 Loss: 0.998214 | Val Acc: 0.766802 loss: 0.704104\n",
            "0.06269805740133327\n",
            "[534/1000] Train Acc: 0.698201 Loss: 0.996954 | Val Acc: 0.767663 loss: 0.703058\n",
            "0.06460551169947415\n",
            "[535/1000] Train Acc: 0.697818 Loss: 0.998026 | Val Acc: 0.768127 loss: 0.700803\n",
            "0.0673239528093641\n",
            "[536/1000] Train Acc: 0.698010 Loss: 0.998152 | Val Acc: 0.766541 loss: 0.704067\n",
            "0.06247472688900413\n",
            "[537/1000] Train Acc: 0.697536 Loss: 0.999345 | Val Acc: 0.767355 loss: 0.700538\n",
            "0.06681618351940388\n",
            "[538/1000] Train Acc: 0.697981 Loss: 0.998442 | Val Acc: 0.767501 loss: 0.702052\n",
            "0.06544918942917477\n",
            "[539/1000] Train Acc: 0.697587 Loss: 0.999067 | Val Acc: 0.767403 loss: 0.702666\n",
            "0.06473687292130392\n",
            "[540/1000] Train Acc: 0.698105 Loss: 0.997315 | Val Acc: 0.767696 loss: 0.701727\n",
            "0.0659691540982632\n",
            "[541/1000] Train Acc: 0.698002 Loss: 0.997545 | Val Acc: 0.768054 loss: 0.702405\n",
            "0.06564843876361082\n",
            "[542/1000] Train Acc: 0.697409 Loss: 0.998938 | Val Acc: 0.767314 loss: 0.701184\n",
            "0.06612947982572936\n",
            "[543/1000] Train Acc: 0.698130 Loss: 0.998473 | Val Acc: 0.767631 loss: 0.700288\n",
            "0.06734310605887839\n",
            "[544/1000] Train Acc: 0.698203 Loss: 0.997240 | Val Acc: 0.768314 loss: 0.701415\n",
            "0.06689858285280104\n",
            "[545/1000] Train Acc: 0.697680 Loss: 0.998498 | Val Acc: 0.768143 loss: 0.702557\n",
            "0.06558644076403175\n",
            "[546/1000] Train Acc: 0.697821 Loss: 0.998586 | Val Acc: 0.768021 loss: 0.702965\n",
            "0.0650566050375484\n",
            "[547/1000] Train Acc: 0.698314 Loss: 0.997099 | Val Acc: 0.768387 loss: 0.700693\n",
            "0.06769423668348351\n",
            "[548/1000] Train Acc: 0.698126 Loss: 0.998442 | Val Acc: 0.768200 loss: 0.702983\n",
            "0.06521683911749832\n",
            "[549/1000] Train Acc: 0.698291 Loss: 0.997582 | Val Acc: 0.767306 loss: 0.702774\n",
            "0.06453171837961735\n",
            "[550/1000] Train Acc: 0.697903 Loss: 0.998222 | Val Acc: 0.768875 loss: 0.700328\n",
            "0.06854678787550084\n",
            "saving drive done\n",
            "saving model with acc 0.769\n",
            "[551/1000] Train Acc: 0.697995 Loss: 0.997974 | Val Acc: 0.766558 loss: 0.702799\n",
            "0.06375918109169554\n",
            "[552/1000] Train Acc: 0.697673 Loss: 0.998413 | Val Acc: 0.766021 loss: 0.702748\n",
            "0.06327360377341174\n",
            "[553/1000] Train Acc: 0.697783 Loss: 0.998944 | Val Acc: 0.767119 loss: 0.701924\n",
            "0.06519473142493215\n",
            "[554/1000] Train Acc: 0.697943 Loss: 0.997758 | Val Acc: 0.766712 loss: 0.702850\n",
            "0.06386187303980573\n",
            "[555/1000] Train Acc: 0.697615 Loss: 0.998548 | Val Acc: 0.767598 loss: 0.702212\n",
            "0.06538609544770735\n",
            "[556/1000] Train Acc: 0.697860 Loss: 0.998884 | Val Acc: 0.768200 loss: 0.702875\n",
            "0.06532533604707025\n",
            "[557/1000] Train Acc: 0.698010 Loss: 0.997496 | Val Acc: 0.766298 loss: 0.702383\n",
            "0.06391489938816985\n",
            "[558/1000] Train Acc: 0.697544 Loss: 0.999385 | Val Acc: 0.768997 loss: 0.699746\n",
            "0.06925039735785632\n",
            "saving drive done\n",
            "saving model with acc 0.769\n",
            "[559/1000] Train Acc: 0.697898 Loss: 0.997630 | Val Acc: 0.767151 loss: 0.702036\n",
            "0.06511474874575252\n",
            "[560/1000] Train Acc: 0.698028 Loss: 0.998209 | Val Acc: 0.765867 loss: 0.704115\n",
            "0.06175160704155025\n",
            "[561/1000] Train Acc: 0.697140 Loss: 0.999407 | Val Acc: 0.768070 loss: 0.701406\n",
            "0.06666388819104552\n",
            "[562/1000] Train Acc: 0.698005 Loss: 0.996892 | Val Acc: 0.767964 loss: 0.701856\n",
            "0.06610870419320847\n",
            "[563/1000] Train Acc: 0.698624 Loss: 0.997589 | Val Acc: 0.767720 loss: 0.699841\n",
            "0.06787940751416677\n",
            "[564/1000] Train Acc: 0.698370 Loss: 0.996523 | Val Acc: 0.767826 loss: 0.702307\n",
            "0.06551898771730102\n",
            "[565/1000] Train Acc: 0.697910 Loss: 0.997332 | Val Acc: 0.766623 loss: 0.702550\n",
            "0.0640730933028606\n",
            "[566/1000] Train Acc: 0.698016 Loss: 0.997527 | Val Acc: 0.767306 loss: 0.701121\n",
            "0.06618456438646048\n",
            "[567/1000] Train Acc: 0.697820 Loss: 0.997199 | Val Acc: 0.767151 loss: 0.700111\n",
            "0.06703976274150458\n",
            "[568/1000] Train Acc: 0.697734 Loss: 0.998035 | Val Acc: 0.768159 loss: 0.701897\n",
            "0.06626252155154377\n",
            "[569/1000] Train Acc: 0.698349 Loss: 0.996700 | Val Acc: 0.767330 loss: 0.701371\n",
            "0.06595901813466454\n",
            "[570/1000] Train Acc: 0.698501 Loss: 0.997600 | Val Acc: 0.766647 loss: 0.703261\n",
            "0.06338662423609831\n",
            "[571/1000] Train Acc: 0.698409 Loss: 0.997240 | Val Acc: 0.767281 loss: 0.701681\n",
            "0.06560035323889135\n",
            "[572/1000] Train Acc: 0.697800 Loss: 0.997495 | Val Acc: 0.766655 loss: 0.702591\n",
            "0.06406437025408585\n",
            "[573/1000] Train Acc: 0.697454 Loss: 0.999390 | Val Acc: 0.767704 loss: 0.702545\n",
            "0.06515925191991401\n",
            "[574/1000] Train Acc: 0.697975 Loss: 0.997608 | Val Acc: 0.768558 loss: 0.700364\n",
            "0.0681940788713451\n",
            "[575/1000] Train Acc: 0.697920 Loss: 0.996998 | Val Acc: 0.766794 loss: 0.702238\n",
            "0.06455511079439069\n",
            "[576/1000] Train Acc: 0.698473 Loss: 0.997097 | Val Acc: 0.767476 loss: 0.703867\n",
            "0.0636093911748079\n",
            "[577/1000] Train Acc: 0.698052 Loss: 0.998210 | Val Acc: 0.766785 loss: 0.703403\n",
            "0.06338209311304754\n",
            "[578/1000] Train Acc: 0.697108 Loss: 0.997796 | Val Acc: 0.767590 loss: 0.702397\n",
            "0.0651932002628064\n",
            "[579/1000] Train Acc: 0.698019 Loss: 0.998939 | Val Acc: 0.767436 loss: 0.702351\n",
            "0.06508519400333512\n",
            "[580/1000] Train Acc: 0.698512 Loss: 0.997070 | Val Acc: 0.766192 loss: 0.703108\n",
            "0.06308434086537107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQrj7o0X0TKn"
      },
      "source": [
        "TODO<br/>\n",
        "loss vs time<br/>\n",
        "acc displacement<br/>\n",
        "model train reload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfUECMFCn5VG"
      },
      "source": [
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PKjtAScPWtr"
      },
      "source": [
        "# # create testing dataset\n",
        "# test_set = TIMITDataset(test, None)\n",
        "# test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# # create model and load weights from checkpoint\n",
        "# model = Classifier().to(device)\n",
        "# model.load_state_dict(torch.load(model_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "940TtCCdoYd0"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84HU5GGjPqR0"
      },
      "source": [
        "# predict = []\n",
        "# model.eval() # set the model to evaluation mode\n",
        "# with torch.no_grad():\n",
        "#     for i, data in enumerate(test_loader):\n",
        "#         inputs = data\n",
        "#         inputs = inputs.to(device)\n",
        "#         outputs = model(inputs)\n",
        "#         _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "\n",
        "#         for y in test_pred.cpu().numpy():\n",
        "#             predict.append(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWDf_C-omElb"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "source": [
        "# with open('prediction.csv', 'w') as f:\n",
        "#     f.write('Id,Class\\n')\n",
        "#     for i, y in enumerate(predict):\n",
        "#         f.write('{},{}\\n'.format(i, y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT6X7f3ZZYCt"
      },
      "source": [
        "# Simple baseline\n",
        "You should able to pass the simple baseline using the sample code provided.\n",
        "# Strong baseline\n",
        "Model architecture (layers? dimension? activation function?)<br> \n",
        "Training (batch size? optimizer? learning rate? epoch?)<br> \n",
        "Tips (batch norm? dropout? regularization?)"
      ]
    }
  ]
}